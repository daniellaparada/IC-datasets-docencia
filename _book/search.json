[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IC-datasets-docencia",
    "section": "",
    "text": "Introducción\nEn el marco de la convocatoria a Proyectos de Asistencia Estadística del Instituto de Cálculo (IC), se propuso la creación de un repositorio curado de datasets para ser utilizados en la enseñanza de la Estadística y la Ciencia de Datos. El objetivo es proporcionar a la comunidad de docentes del IC, y de otros centros universiatrios, una fuente centralizada de datos abiertos que cubra una amplia variedad de temas y áreas de aplicación.\nLos datasets fueron revisados para asegurar que sean apropiados para su uso en cursos que dicta el IC, y en los capítulos que siguen se proporcionan descripciones detalladas para cada uno, así como breves sugerencias de uso reproducible. En ese sentido, los ejemplos allí desarrollados son simples vehículos para poner a disposición los datos e ilustrar algunas de sus características.\n\nEn las secciones numeradas, cada dataset está preparado para su uso en R y se acompaña con una documentación clara y concisa que incluye un diccionario de variables, la fuente de los datos y un código de muestra para su preparación.\nEn el Anexo, se incluyen datasets documentados sin ejemplos desarrollados, pero con una grilla que sugiere posibles temas afines.\n\nLos datasets también se encuentran disponibles en la librería datosIC.\n\n\nCódigo\nrequire(devtools)\ndevtools::install_github(\"daniellaparada/datosIC\")\nlibrary(datosIC)"
  },
  {
    "objectID": "01_regresion.html",
    "href": "01_regresion.html",
    "title": "1  Regresión",
    "section": "",
    "text": "2 Acerca de los datos\nA continuación, se detallan aspectos de los conjuntos de datos que conformaron el dataset reducido para el desarrollo del ejemplo, a la vez que se incluyen las fuentes de los datos y el código utilizado para pre-procesarlo con la sintaxis de tidyverse. De esta forma, puede fácilmente replicarse y/o adaptarse si así se lo desea.\nTambién se incluye el enlace de descarga al dataset reducido, temp-bici.csv, con el que se desarrolló el ejemplo.\nLas librerías usadas para el desarrollo de este ejemplo, así como la información de la sesión de R, se muestran en el código que sigue.\nCódigo\nrequire(tidyverse)\nrequire(ggfortify)\nrequire(plotly)\nrequire(kableExtra)\nrequire(knitr)\nrequire(devtools)\nCódigo\nsessionInfo()\n\n\nR version 4.2.3 (2023-03-15 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 22621)\n\nMatrix products: default\n\nlocale:\n[1] LC_COLLATE=Spanish_Argentina.utf8  LC_CTYPE=Spanish_Argentina.utf8   \n[3] LC_MONETARY=Spanish_Argentina.utf8 LC_NUMERIC=C                      \n[5] LC_TIME=Spanish_Argentina.utf8    \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] datosIC_0.0.0.9000 devtools_2.4.5     usethis_2.1.6      knitr_1.42        \n [5] kableExtra_1.3.4   plotly_4.10.1      ggfortify_0.4.16   lubridate_1.9.2   \n [9] forcats_1.0.0      stringr_1.5.0      dplyr_1.1.2        purrr_1.0.1       \n[13] readr_2.1.4        tidyr_1.3.0        tibble_3.2.1       ggplot2_3.4.2     \n[17] tidyverse_2.0.0   \n\nloaded via a namespace (and not attached):\n [1] nlme_3.1-162      fs_1.6.1          webshot_0.5.4     httr_1.4.5       \n [5] tools_4.2.3       profvis_0.3.7     utf8_1.2.3        R6_2.5.1         \n [9] lazyeval_0.2.2    mgcv_1.8-42       colorspace_2.1-0  urlchecker_1.0.1 \n[13] withr_2.5.0       tidyselect_1.2.0  gridExtra_2.3     prettyunits_1.1.1\n[17] processx_3.8.0    curl_5.0.0        compiler_4.2.3    cli_3.6.1        \n[21] rvest_1.0.3       xml2_1.3.3        labeling_0.4.2    scales_1.2.1     \n[25] callr_3.7.3       systemfonts_1.0.4 digest_0.6.31     rmarkdown_2.21   \n[29] svglite_2.1.1     pkgconfig_2.0.3   htmltools_0.5.5   sessioninfo_1.2.2\n[33] fastmap_1.1.1     highr_0.10        htmlwidgets_1.6.2 rlang_1.1.0      \n[37] rstudioapi_0.14   shiny_1.7.4       generics_0.1.3    farver_2.1.1     \n[41] jsonlite_1.8.4    crosstalk_1.2.0   magrittr_2.0.3    Matrix_1.5-4     \n[45] Rcpp_1.0.10       munsell_0.5.0     fansi_1.0.4       lifecycle_1.0.3  \n[49] stringi_1.7.12    yaml_2.3.7        pkgbuild_1.4.0    grid_4.2.3       \n[53] promises_1.2.0.1  crayon_1.5.2      miniUI_0.1.1.1    lattice_0.21-8   \n[57] splines_4.2.3     hms_1.1.3         ps_1.7.4          pillar_1.9.0     \n[61] pkgload_1.3.2     glue_1.6.2        evaluate_0.20     data.table_1.14.8\n[65] remotes_2.4.2     vctrs_0.6.1       tzdb_0.3.0        httpuv_1.6.9     \n[69] gtable_0.3.3      cachem_1.0.7      xfun_0.39         mime_0.12        \n[73] xtable_1.8-4      later_1.3.0       viridisLite_0.4.2 memoise_2.0.1    \n[77] timechange_0.2.0  ellipsis_0.3.2"
  },
  {
    "objectID": "01_regresion.html#exploración-inicial",
    "href": "01_regresion.html#exploración-inicial",
    "title": "1  Regresión",
    "section": "1.1 Exploración inicial",
    "text": "1.1 Exploración inicial\nEn el dataset reducido temp-bici.csv se incluyen datos de viajes con duración entre 5 y 60 minutos, cualquier día de la semana, desde el 4 de junio de 2022 hasta el 1ro de mayo de 2023.\nEl dataset temp-bici.csv se encuentra acá. A continuación se muestran 10 datos de dicho conjunto.\n\n\nCódigo\n#datos &lt;- read_csv(\"./fuente/01_regresion/temp-bici.csv\")\n\ndevtools::install_github(\"daniellaparada/datosIC\")\nlibrary(datosIC)\ndata(tempbici)\n\ndatos &lt;- tempbici\n\n\n\n\n\nDataset reducido\n\n\nfecha\nn\ntmin\ntmax\ntmed\ndia\ntipo_dia\n\n\n\n\n2022-06-04\n2495\n9.2\n15.1\n12.15\nsábado\nFin de semana\n\n\n2022-06-05\n1925\n9.1\n14.8\n11.95\ndomingo\nFin de semana\n\n\n2022-06-06\n8308\n8.8\n13.5\n11.15\nlunes\nLunes a viernes\n\n\n2022-06-07\n8137\n7.3\n11.5\n9.40\nmartes\nLunes a viernes\n\n\n2022-06-08\n8854\n7.3\n11.6\n9.45\nmiércoles\nLunes a viernes\n\n\n2022-06-09\n8803\n8.3\n16.1\n12.20\njueves\nLunes a viernes\n\n\n2022-06-10\n6890\n4.2\n11.5\n7.85\nviernes\nLunes a viernes\n\n\n2022-06-11\n2305\n4.6\n15.7\n10.15\nsábado\nFin de semana\n\n\n2022-06-12\n2561\n6.4\n14.6\n10.50\ndomingo\nFin de semana\n\n\n2022-06-13\n9120\n7.4\n16.2\n11.80\nlunes\nLunes a viernes\n\n\n\n\n\n\n\nComo puede verse en el siguiente gráfico, la cantidad de registros de viajes de esa duración varía en función de la temperatura máxima del día, y de si se trata de un día de la semana (lunes a viernes) o fin de semana (sábado y domingo).\n\n\nCódigo\nggplotly(\n  ggplot(data = filter(datos), aes(\n    x = tmax,\n    y = n,\n    key = fecha,\n    col = tipo_dia\n  )) +\n    labs(x = \"Temperatura máxima\", y = \"Cantidad de usos de Ecobici\") +\n    geom_point() +\n    theme_classic(),\n  source = \"select\",\n  tooltip = c(\"key\")\n)\n\n\n\n\n\n\nEn el gráfico se observa una tendencia similar en cuanto a cómo varía la cantidad de usos diarios del sistema en función de la temperatura máxima del día. Sin embargo, y aunque la tendencia es similar, la cantidad de usos se reduce notablemente los fines de semana.\nEl sistema de Ecobici es un sistema público de transporte y, como tal, es razonable que su uso sea intensivo durante los días hábiles, lo que explica las tendencias separadas que se ven en los gráficos anteriores. Sin embargo, en el conjunto de datos no se tiene información de feriados, por lo que hay algunas observaciones del grupo verde (lunes a viernes) que se observan próximos a los del grupo rojo (fines de semana). El 1ro de mayo es una de ellas. También hay fines de semana que coinciden con feriados en los que típicamente hay menos movimiento, como ocurre con la observación roja que corresponde al 1ro de enero. Y también ocurre lo contrario: fines de semana de uso atípico, como el de aquel domingo 18 de diciembre de 2022 en que Argentina se coronó campeón Mundial, y cuya observación, aunque de color rojo (domingo), se ubica dentro de la nube de puntos verdes.\nEste dataset no cuenta con datos de precipitaciones para las fechas observadas, lo que podría ayudar a explicar las mermas en el uso del sistema de Ecobici de ciertas fechas [para más información sobre esto, puede consultarse la Sección 3]. Sin embargo, es notable ver que existe cierta tendencia entre la intensidad del uso y la temperatura. Y tal tendencia no obedece únicamente a una cuestión de temporadas climáticas (estaciones del año, por ejemplo). Esto puede observarse en los siguientes gráficos, en donde se muestra que la evolución de la temperatura en función de la fecha del año no exhibe el mismo comportamiento que el uso del sistema Ecobici.\n\n\nCódigo\nggplotly(\n  ggplot(data = filter(datos), aes(\n    x = fecha,\n    y = n,\n    key = tmax,\n    col = tipo_dia\n  )) +\n    labs(x = \"Fecha\", y = \"Cantidad de usos de Ecobici\") +\n    geom_point() +\n    theme_classic(),\n  source = \"select\",\n  tooltip = c(\"key\")\n)\n\n\n\n\n\n\n\n\nCódigo\nggplotly(\n  ggplot(data = filter(datos), aes(x = fecha, y = tmax)) +\n    labs(x = \"Fecha\", y = \"Temperatura máxima\") +\n    geom_point() +\n    theme_classic(),\n  source = \"select\",\n  tooltip = c(\"key\")\n)\n\n\n\n\n\n\nEsto sugiere que un ajuste lineal podría no ser el más adecuado para modelar la relación entre estas variables. En la siguiente sección, se prueban ajustes lineales y cuadráticos para explicar el uso del sistema Ecobici en función de la temperatura máxima diaria, tanto para días de semana como para fines de semana."
  },
  {
    "objectID": "01_regresion.html#ajuste-lineal",
    "href": "01_regresion.html#ajuste-lineal",
    "title": "1  Regresión",
    "section": "1.2 Ajuste lineal",
    "text": "1.2 Ajuste lineal\nEl ajuste lineal sobre el dataset completo muestra lo que anticipaban los gráficos anteriores. Aun cuando se ajusta por tipo de día, no se capta por completo la relación que se observa entre las variables a partir de los datos.\n\n\nCódigo\nggplotly(\n  ggplot(data = filter(datos), aes(\n    x = tmax,\n    y = n,\n    color = tipo_dia,\n    key = fecha\n  )) +\n    labs(x = \"Temperatura máxima\", y = \"Cantidad de usos de Ecobici\") +\n    geom_point() +\n    geom_smooth(method = \"lm\") +\n    theme_classic(),\n  source = \"select\",\n  tooltip = c(\"key\")\n)\n\n\n\n\n\n\n\n1.2.1 Gráficos de diagnóstico\nLos gráficos de diagnóstico exhiben estructura en los residuos en ambos ajustes.\n\n1.2.1.1 Día de semana\n\n\nCódigo\nautoplot(lm(n ~ tmax,\n            data = datos[datos$tipo_dia == \"Lunes a viernes\",]),\n         label.size = 3)\n\n\n\n\n\nLas observaciones 121, 135 y 236 corresponden a los siguientes casos (todos feriados nacionales).\n\n\n\n\n\nfecha\nn\ntmin\ntmax\ntmed\ndia\ntipo_dia\n\n\n\n\n2022-11-21\n2422\n14.7\n19.6\n17.15\nlunes\nLunes a viernes\n\n\n2022-12-09\n3500\n22.4\n34.6\n28.50\nviernes\nLunes a viernes\n\n\n2023-05-01\n18\n11.1\n19.5\n15.30\nlunes\nLunes a viernes\n\n\n\n\n\n\n\n\n\n1.2.1.2 Fin de semana\n\n\nCódigo\nautoplot(lm(n ~ tmax,\n            data = datos[datos$tipo_dia == \"Fin de semana\", ]),\n         label.size = 3)\n\n\n\n\n\nLas observaciones 13, 42, 58 y 62 corresponden a los siguientes casos.\n\n\n\n\n\nfecha\nn\ntmin\ntmax\ntmed\ndia\ntipo_dia\n\n\n\n\n2022-07-16\n1403\n8.4\n11.7\n10.05\nsábado\nFin de semana\n\n\n2022-10-23\n5392\n10.8\n18.8\n14.80\ndomingo\nFin de semana\n\n\n2022-12-18\n7660\n19.5\n27.2\n23.35\ndomingo\nFin de semana\n\n\n2023-01-01\n12\n19.5\n26.6\n23.05\ndomingo\nFin de semana"
  },
  {
    "objectID": "01_regresion.html#ajuste-cuadrático",
    "href": "01_regresion.html#ajuste-cuadrático",
    "title": "1  Regresión",
    "section": "1.3 Ajuste cuadrático",
    "text": "1.3 Ajuste cuadrático\nEl ajuste cuadrático mejora el ajuste anterior y parece modelar mejor la estructura observada.\n\n\nCódigo\nggplotly(\n  ggplot(data = filter(datos), aes(\n    x = tmax,\n    y = n,\n    color = tipo_dia,\n    key = fecha\n  )) +\n    labs(x = \"Temperatura máxima\", y = \"Cantidad de usos de Ecobici\") +\n    geom_point() +\n    geom_smooth(method = \"lm\",\n                formula = y ~ poly(x, 2)) +\n    theme_classic(),\n  source = \"select\",\n  tooltip = c(\"key\")\n)\n\n\n\n\n\n\n\n1.3.1 Gráficos de diagnóstico\nEn efecto, los gráficos de diagnóstico confirman que parte de la estructura de los residuos fue resuelta.\n\n1.3.1.1 Día de semana\n\n\nCódigo\nautoplot(lm(n ~ poly(tmax, 2),\n            data = datos[datos$tipo_dia == \"Lunes a viernes\", ]),\n         label.size = 3)\n\n\n\n\n\nLas observaciones 10, 121, 135, 220 y 236 corresponden a los siguientes casos (todos feriados nacionales).\n\n\n\n\n\nfecha\nn\ntmin\ntmax\ntmed\ndia\ntipo_dia\n\n\n\n\n2022-06-17\n2397\n5.8\n13.2\n9.50\nviernes\nLunes a viernes\n\n\n2022-11-21\n2422\n14.7\n19.6\n17.15\nlunes\nLunes a viernes\n\n\n2022-12-09\n3500\n22.4\n34.6\n28.50\nviernes\nLunes a viernes\n\n\n2023-04-07\n3261\n19.1\n23.1\n21.10\nviernes\nLunes a viernes\n\n\n2023-05-01\n18\n11.1\n19.5\n15.30\nlunes\nLunes a viernes\n\n\n\n\n\n\n\n\n\n1.3.1.2 Fin de semana\n\n\nCódigo\nautoplot(lm(n ~ poly(tmax, 2),\n            data = datos[datos$tipo_dia == \"Fin de semana\", ]),\n         label.size = 3)\n\n\n\n\n\nLas observaciones 42, 58 y 62 corresponden a los siguientes casos.\n\n\n\n\n\nfecha\nn\ntmin\ntmax\ntmed\ndia\ntipo_dia\n\n\n\n\n2022-10-23\n5392\n10.8\n18.8\n14.80\ndomingo\nFin de semana\n\n\n2022-12-18\n7660\n19.5\n27.2\n23.35\ndomingo\nFin de semana\n\n\n2023-01-01\n12\n19.5\n26.6\n23.05\ndomingo\nFin de semana"
  },
  {
    "objectID": "01_regresion.html#ajuste-lineal-para-días-templados",
    "href": "01_regresion.html#ajuste-lineal-para-días-templados",
    "title": "1  Regresión",
    "section": "1.4 Ajuste lineal para días templados",
    "text": "1.4 Ajuste lineal para días templados\nEl ajuste podría ser lineal para explicar el uso del sistema Ecobici para días templados, por ejemplo, con temperaturas máximas inferiores a los 25°C.\n\n\nCódigo\nggplotly(\n  ggplot(\n    data = filter(datos, tmax &lt; 25),\n    aes(\n      x = tmax,\n      y = n,\n      color = tipo_dia,\n      key = fecha\n    )\n  ) +\n    labs(x = \"Temperatura máxima (menor que 25°C)\", y = \"Cantidad de usos de Ecobici\") +\n    geom_point() +\n    geom_smooth(method = \"lm\") +\n    theme_classic(),\n  source = \"select\",\n  tooltip = c(\"key\")\n)\n\n\n\n\n\n\n\n1.4.1 Gráficos de diagnóstico\nLos gráficos de diagnóstico exhiben menos estructura en los residuos respecto del ajuste lineal que cuando se consideraban todas las posibles temperaturas máximas. Es decir, parece razonable suponer que la tendencia en el uso del sistema Ecobici es creciente en relación con la temperatura máxima, siempre que esta no exceda cierto límite.\n\n1.4.1.1 Día de semana\n\n\nCódigo\nautoplot(lm(n ~ tmax,\n            data = datos[(datos$tipo_dia == \"Lunes a viernes\" &\n                            datos$tmax &lt; 25), ]),\n         label.size = 3)\n\n\n\n\n\nLas observaciones 10, 110, 122 y 135 corresponden a los siguientes casos (todos feriados nacionales).\n\n\n\n\n\nfecha\nn\ntmin\ntmax\ntmed\ndia\ntipo_dia\n\n\n\n\n2022-06-17\n2397\n5.8\n13.2\n9.50\nviernes\nLunes a viernes\n\n\n2022-11-21\n2422\n14.7\n19.6\n17.15\nlunes\nLunes a viernes\n\n\n2023-04-07\n3261\n19.1\n23.1\n21.10\nviernes\nLunes a viernes\n\n\n2023-05-01\n18\n11.1\n19.5\n15.30\nlunes\nLunes a viernes\n\n\n\n\n\n\n\n\n\n1.4.1.2 Fin de semana\n\n\nCódigo\nautoplot(lm(n ~ tmax,\n            data = datos[(datos$tipo_dia == \"Fin de semana\" &\n                            datos$tmax &lt; 25), ]),\n         label.size = 3)\n\n\n\n\n\nLas observaciones 42, 46 y 48 corresponden a los siguientes casos.\n\n\n\n\n\nfecha\nn\ntmin\ntmax\ntmed\ndia\ntipo_dia\n\n\n\n\n2022-10-23\n5392\n10.8\n18.8\n14.80\ndomingo\nFin de semana\n\n\n2022-12-24\n2079\n17.5\n24.2\n20.85\nsábado\nFin de semana\n\n\n2023-02-18\n3614\n9.4\n23.7\n16.55\nsábado\nFin de semana"
  },
  {
    "objectID": "01_regresion.html#sobre-el-dataset-de-temperatura",
    "href": "01_regresion.html#sobre-el-dataset-de-temperatura",
    "title": "1  Regresión",
    "section": "2.1 Sobre el dataset de temperatura",
    "text": "2.1 Sobre el dataset de temperatura\nLos datos de este ejemplo corresponden a datos de temperatura de los últimos 365 días tomados del Servicio Meterológico Nacional (disponibles acá). En particular, se considerarán los datos procesados de temperatura mínimas y máximas registradas en Aeroparque desde el 4 de junio de 2022 al 3 de julio de 2023.\n\n\nCódigo\ntemperatura &lt;-\n  read_table(\"./fuente/01_regresion/registro_temperatura365d_smn.txt\") %&gt;%\n  slice(2:n()) %&gt;%\n  filter(NOMBRE == \"AEROPARQUE\") %&gt;%\n  select(1:3) %&gt;%\n  mutate(\n    fecha = dmy(FECHA),\n    tmin = as.double(TMIN),\n    tmax = as.double(TMAX),\n    tmed = 0.5 * (tmin + tmax)\n  )"
  },
  {
    "objectID": "01_regresion.html#sobre-el-dataset-de-ecobici",
    "href": "01_regresion.html#sobre-el-dataset-de-ecobici",
    "title": "1  Regresión",
    "section": "2.2 Sobre el dataset de Ecobici",
    "text": "2.2 Sobre el dataset de Ecobici\nLos datos de este ejemplo corresponden a datos de uso del sistema Ecobici de la Ciudad de Buenos Aires (disponibles acá). En particular, se considerarán los datos de los años 2022 y 2023 correspondientes a viajes de entre 5 minutos y 1 hora de duración.\nEcobici es el sistema de transporte público de bicicletas de la Ciudad de Buenos Aires, que tiene estaciones automáticas con bicicletas a disposición las 24 horas, todos los días del año. El sistema es gratuito para todas las personas residentes del país de lunes a viernes (días hábiles) con hasta cuatro viajes de 30 minutos cada uno. Sin embargo, si se utiliza por un tiempo mayor que el indicado o durante los fines de semana, existen diferentes pases con variados costos. A modo de referencia, el pase que habilita a hacer 6 viajes diarios de hasta 60 minutos cada uno cualquier día de la semana tiene un costo de $1.785 (junio 2023).\n\n\nCódigo\ntrips_2022 &lt;- read_csv(\n  \"./fuente/01_regresion/trips_2022.csv\",\n  col_types = cols(fecha_origen_recorrido = col_datetime(format = \"%Y-%m-%d %H:%M:%S\"))\n) %&gt;%\n  mutate(fecha = format(as_date(ymd_hms(\n    fecha_destino_recorrido\n  )))) %&gt;%\n  filter(duracion_recorrido &gt; 300 && duracion_recorrido &lt; 3600) %&gt;%\n  group_by(fecha) %&gt;%\n  count() %&gt;%\n  mutate(fecha = as_date(fecha))\n\ntrips_2023 &lt;- read_csv(\n  \"./fuente/01_regresion/trips_2023.csv\",\n  col_types = cols(fecha_origen_recorrido = col_datetime(format = \"%Y-%m-%d %H:%M:%S\"))\n) %&gt;%\n  mutate(fecha = format(as_date(ymd_hms(\n    fecha_destino_recorrido\n  )))) %&gt;%\n  filter(duracion_recorrido &gt; 300 && duracion_recorrido &lt; 3600) %&gt;%\n  group_by(fecha) %&gt;%\n  count() %&gt;%\n  mutate(fecha = as_date(fecha))\n\ntrips &lt;- rbind(trips_2022, trips_2023)"
  },
  {
    "objectID": "01_regresion.html#dataset-pre-procesado-temp-bici.csv",
    "href": "01_regresion.html#dataset-pre-procesado-temp-bici.csv",
    "title": "1  Regresión",
    "section": "2.3 Dataset pre-procesado: temp-bici.csv",
    "text": "2.3 Dataset pre-procesado: temp-bici.csv\nPara reducir los datos al estudio de interés, se crea un dataset conjunto, temp-bici.csv, a partir de los datos de temperatura y de uso del sistema Ecobici en el que se dispone de las siguientes variables.\n\nfecha: fecha, en el formato año-mes-día.\nn: cantidad de registros de uso del sistema EcoBici en la fecha indicada.\ntmin: temperatura mínima registrada en esa fecha.\ntmax: temperatura máxima registrada en esa fecha.\ntmed: temperatura media, construida como el promedio entre la temperatura mínima y máxima de esa fecha.\ndia: día de la semana de la fecha indicada.\ntipo_dia: tipo de día (Fin de semana o Lunes a viernes) de la fecha indicada.\n\n\n\nCódigo\ntrips &lt;- trips %&gt;%\n  filter(fecha &gt;= min(temperatura$fecha) &\n           fecha &lt;= max(temperatura$fecha))\n\ndatos &lt;-\n  left_join(trips, temperatura, by = c(\"fecha\" = \"fecha\")) %&gt;%\n  drop_na() %&gt;%\n  mutate(\n    dia = weekdays(fecha),\n    tipo_dia = ifelse(dia %in% c(\"sábado\", \"domingo\"), \"Fin de semana\", \"Lunes a viernes\")\n  ) %&gt;%\n  select(c(1, 2, 6:10)) \n\n\nEl dataset también está disponible en la librería datosIC bajo el nombre de tempbici.\n\n\nCódigo\ndevtools::install_github(\"daniellaparada/datosIC\")\nlibrary(datosIC)\ndata(tempbbici)\n\n\n\n\nCódigo\nknitr::kable(tempbici[1:10,], caption = \"Dataset reducido disponible en la librería 'datosIC'.\")\n\n\n\nDataset reducido disponible en la librería 'datosIC'.\n\n\nfecha\nn\ntmin\ntmax\ntmed\ndia\ntipo_dia\n\n\n\n\n2022-06-04\n2495\n9.2\n15.1\n12.15\nsábado\nFin de semana\n\n\n2022-06-05\n1925\n9.1\n14.8\n11.95\ndomingo\nFin de semana\n\n\n2022-06-06\n8308\n8.8\n13.5\n11.15\nlunes\nLunes a viernes\n\n\n2022-06-07\n8137\n7.3\n11.5\n9.40\nmartes\nLunes a viernes\n\n\n2022-06-08\n8854\n7.3\n11.6\n9.45\nmiércoles\nLunes a viernes\n\n\n2022-06-09\n8803\n8.3\n16.1\n12.20\njueves\nLunes a viernes\n\n\n2022-06-10\n6890\n4.2\n11.5\n7.85\nviernes\nLunes a viernes\n\n\n2022-06-11\n2305\n4.6\n15.7\n10.15\nsábado\nFin de semana\n\n\n2022-06-12\n2561\n6.4\n14.6\n10.50\ndomingo\nFin de semana\n\n\n2022-06-13\n9120\n7.4\n16.2\n11.80\nlunes\nLunes a viernes"
  },
  {
    "objectID": "02_regresion_multiple.html",
    "href": "02_regresion_multiple.html",
    "title": "2  Regresión múltiple",
    "section": "",
    "text": "3 Acerca de los datos\nA continuación, se detallan aspectos de los datasets que conformaron el dataset reducido para el desarrollo del ejemplo, a la vez que se incluyen las fuentes de los datos y el código utilizado para pre-procesarlo con la sintaxis de tidyverse. De esta forma, puede fácilmente replicarse y/o adaptarse si así se lo desea.\nTambién se incluye el enlace de descarga al dataset reducido, clima-bici.csv, con el que se desarrolló el ejemplo.\nLas librerías usadas para el desarrollo de este ejemplo, así como la información de la sesión de R, se muestran en el código que sigue.\nCódigo\nrequire(tidyverse)\nrequire(ggfortify)\nrequire(plotly)\nrequire(kableExtra)\nrequire(knitr)\nrequire(devtools)\nCódigo\nsessionInfo()\n\n\nR version 4.2.3 (2023-03-15 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 22621)\n\nMatrix products: default\n\nlocale:\n[1] LC_COLLATE=Spanish_Argentina.utf8  LC_CTYPE=Spanish_Argentina.utf8   \n[3] LC_MONETARY=Spanish_Argentina.utf8 LC_NUMERIC=C                      \n[5] LC_TIME=Spanish_Argentina.utf8    \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] datosIC_0.0.0.9000 devtools_2.4.5     usethis_2.1.6      knitr_1.42        \n [5] kableExtra_1.3.4   plotly_4.10.1      ggfortify_0.4.16   lubridate_1.9.2   \n [9] forcats_1.0.0      stringr_1.5.0      dplyr_1.1.2        purrr_1.0.1       \n[13] readr_2.1.4        tidyr_1.3.0        tibble_3.2.1       ggplot2_3.4.2     \n[17] tidyverse_2.0.0   \n\nloaded via a namespace (and not attached):\n [1] nlme_3.1-162      fs_1.6.1          webshot_0.5.4     httr_1.4.5       \n [5] tools_4.2.3       profvis_0.3.7     utf8_1.2.3        R6_2.5.1         \n [9] lazyeval_0.2.2    mgcv_1.8-42       colorspace_2.1-0  urlchecker_1.0.1 \n[13] withr_2.5.0       tidyselect_1.2.0  gridExtra_2.3     prettyunits_1.1.1\n[17] processx_3.8.0    curl_5.0.0        compiler_4.2.3    cli_3.6.1        \n[21] rvest_1.0.3       xml2_1.3.3        labeling_0.4.2    scales_1.2.1     \n[25] callr_3.7.3       systemfonts_1.0.4 digest_0.6.31     rmarkdown_2.21   \n[29] svglite_2.1.1     pkgconfig_2.0.3   htmltools_0.5.5   sessioninfo_1.2.2\n[33] fastmap_1.1.1     highr_0.10        htmlwidgets_1.6.2 rlang_1.1.0      \n[37] rstudioapi_0.14   shiny_1.7.4       generics_0.1.3    farver_2.1.1     \n[41] jsonlite_1.8.4    crosstalk_1.2.0   magrittr_2.0.3    Matrix_1.5-4     \n[45] Rcpp_1.0.10       munsell_0.5.0     fansi_1.0.4       lifecycle_1.0.3  \n[49] yaml_2.3.7        stringi_1.7.12    pkgbuild_1.4.0    grid_4.2.3       \n[53] promises_1.2.0.1  crayon_1.5.2      miniUI_0.1.1.1    lattice_0.21-8   \n[57] splines_4.2.3     hms_1.1.3         ps_1.7.4          pillar_1.9.0     \n[61] pkgload_1.3.2     glue_1.6.2        evaluate_0.20     data.table_1.14.8\n[65] remotes_2.4.2     vctrs_0.6.1       tzdb_0.3.0        httpuv_1.6.9     \n[69] gtable_0.3.3      cachem_1.0.7      xfun_0.39         mime_0.12        \n[73] xtable_1.8-4      later_1.3.0       viridisLite_0.4.2 memoise_2.0.1    \n[77] timechange_0.2.0  ellipsis_0.3.2"
  },
  {
    "objectID": "02_regresion_multiple.html#exploración-inicial",
    "href": "02_regresion_multiple.html#exploración-inicial",
    "title": "2  Regresión múltiple",
    "section": "2.1 Exploración inicial",
    "text": "2.1 Exploración inicial\nEn el dataset reducido clima-bici.csv se incluyen datos de viajes con duración entre 5 y 60 minutos, cualquier día de la semana, durante el año 2022 y se encuentra disponible acá. A continuación, se muestran 10 datos de dicho conjunto.\n\n\nCódigo\n#datos &lt;- read_csv(\"./fuente/02_regresion_multiple/clima-bici.csv\")\n\ndevtools::install_github(\"daniellaparada/datosIC\")\nlibrary(datosIC)\ndata(climabici)\n\ndatos &lt;- climabici\n\n\n\n\n\nDataset reducido, primeras 10 observaciones.\n\n\nfecha\nn\ntavg\ntmin\ntmax\nprcp\ndia\ntipo_dia\nlluvia\n\n\n\n\n2022-01-01\n2233\n24.8\n20.7\n29.1\n2.3\nsábado\nFin de semana\nLlueve\n\n\n2022-01-02\n3162\n24.7\n19.2\n29.7\n1.5\ndomingo\nFin de semana\nLlueve\n\n\n2022-01-03\n7389\n27.9\n24.1\n31.7\n6.7\nlunes\nLunes a viernes\nLlueve\n\n\n2022-01-04\n7215\n28.2\n24.8\n32.6\n3.9\nmartes\nLunes a viernes\nLlueve\n\n\n2022-01-05\n7611\n21.7\n16.7\n31.7\n0.0\nmiércoles\nLunes a viernes\nNo llueve\n\n\n2022-01-06\n8336\n22.1\n18.8\n25.7\n0.0\njueves\nLunes a viernes\nNo llueve\n\n\n2022-01-07\n8079\n23.8\n20.6\n26.6\n0.0\nviernes\nLunes a viernes\nNo llueve\n\n\n2022-01-08\n3529\n24.4\n21.8\n27.1\n0.0\nsábado\nFin de semana\nNo llueve\n\n\n2022-01-09\n3453\n24.9\n20.9\n29.5\n0.0\ndomingo\nFin de semana\nNo llueve\n\n\n2022-01-10\n7825\n26.9\n22.8\n31.3\n0.0\nlunes\nLunes a viernes\nNo llueve\n\n\n\n\n\n\n\nComo puede verse en el siguiente gráfico, la cantidad de registros de viajes de esa duración varía en función de la temperatura del día, de las precipitaciones, y de si se trata de un día de la semana (lunes a viernes) o fin de semana (sábado y domingo), entre otros.\n\n\n\n\n\n\nEl sistema de Ecobici es un sistema público de transporte y, como tal, es razonable que su uso sea intensivo durante los días hábiles, lo que explica las tendencias separadas que se ven en el gráfico anterior. Sin embargo, en el conjunto de datos no se tiene información de feriados, por lo que hay algunas observaciones del grupo verde (lunes a viernes) que se observan próximos a los del grupo rojo (fines de semana). También hay fines de semana que coinciden con feriados en los que típicamente hay menos movimiento; y también ocurre lo contrario: fines de semana de uso atípico, como el de aquel domingo 18 de diciembre de 2022 en que Argentina se coronó campeón Mundial, y cuya observación, aunque de color rojo (domingo), se ubica dentro de la nube de puntos verdes.\nEl tamaño de los puntos del gráfico anterior es proporcional al nivel de precipitación (en mm) del día. Sin embargo, una observación (27/02/22) registra una precipitación tan alta (más de 240 mm) que limita la posibilidad de apreciar qué ocurre, en general, cuando llueve y las lluvias no son tan extremas en términos de precipitación acumulada (acá una noticia al respecto).\n\n\n\nDatos del 27 de febrero.\n\n\nfecha\nn\ntavg\ntmin\ntmax\nprcp\ndia\ntipo_dia\nlluvia\n\n\n\n\n2022-02-27\n1573\n23.1\n21.8\n25.6\n246.9\ndomingo\nFin de semana\nLlueve\n\n\n\n\n\n\n\nPara lo que sigue, removemos esa observación.\n\n\n\n\n\n\nEn efecto, los puntos más grandes de cada “nube” de color se encuentran ubicados por debajo de la tendencia general del resto de los puntos de su clase. Es decir, los días con mayor nivel de precipitación, la cantidad de usos del sistema de Ecobici se reduce notablemente, tanto para días hábiles como fines de semana. En particular, las tendencias por tipo de día se observan más “limpias” cuando se filtra por días en los que no se registran precipitaciones, como se observa a continuación.\n\n\n\n\n\n\n\n2.1.1 Primeros ajustes con temperatura y precipitaciones\nSe incorpora la variable de precipitaciones (prcp) además de la temperatura (tavg) a un modelo de regresión para predecir la cantidad de bicicletas utilizadas por día (n). En esta primera exploración, no se distingue por tipo de día (tipo_dia).\n\n\nCódigo\nfitlm = lm(n ~ tavg + prcp, data = datos)\n\n\n\n\n\nCall:\nlm(formula = n ~ tavg + prcp, data = datos)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-7328.4 -3839.4   707.9  3262.7  5908.4 \n\nCoefficients:\n            Estimate Std. Error t value             Pr(&gt;|t|)    \n(Intercept)  6737.93     671.79  10.030 &lt; 0.0000000000000002 ***\ntavg           83.27      36.56   2.278              0.02333 *  \nprcp         -116.44      39.00  -2.986              0.00302 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3677 on 359 degrees of freedom\nMultiple R-squared:  0.03235,   Adjusted R-squared:  0.02696 \nF-statistic: 6.001 on 2 and 359 DF,  p-value: 0.002733\n\n\nEl coeficiente estimado para la variable del nivel de precipitación es \\(-116.44\\), lo que sugiere que el incremento en el nivel de lluvia hace disminuir la cantidad de bicicletas que se usan en un día, razonablemente con lo esperado y observado.\nLo contrario ocurre con la temperatura, cuyo coeficiente estimado es \\(83.27\\), que sugiere que el aumento de temperatura incrementa el uso del sistema Ecobici.\nPara lo que sigue, trabajamos con una reducción inicial de los datos a los días “lluviososo y templados”, es decir, a las observaciones que registran precipitación no nula y temperatura media inferior a 25°, e incorporamos la variable de precipitaciones en un modelo de regresión múltiple.\n\n\nCódigo\ndatosfilt &lt;- filter(datos,\n                    lluvia == \"Llueve\",\n                    tavg &lt; 25)\nggplotly(\n  ggplot(data = datosfilt, aes(\n    x = tavg,\n    y = n,\n    key = fecha,\n    size = prcp,\n    color = tipo_dia\n  )) +\n    labs(x = \"Temperatura media\", y = \"Cantidad de usos de Ecobici\") +\n    geom_point() +\n    geom_smooth(method = \"lm\",\n                formula = y ~ x) +\n    theme_classic(),\n  source = \"select\",\n  tooltip = c(\"key\")\n)\n\n\n\n\n\n\n\n2.1.1.1 Días de semana lluviosos y templados\n\n\nCódigo\ndatosfilt &lt;- filter(datos,\n                    lluvia == \"Llueve\",\n                    tipo_dia == \"Lunes a viernes\",\n                    tavg &lt; 25)\nfitlm = lm(n ~ tavg + prcp, data = datosfilt)\nsummary(fitlm)\n\n\n\nCall:\nlm(formula = n ~ tavg + prcp, data = datosfilt)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6996.6 -1537.5   -29.4  2145.9  4274.0 \n\nCoefficients:\n            Estimate Std. Error t value  Pr(&gt;|t|)    \n(Intercept)  6376.65    1422.03   4.484 0.0000386 ***\ntavg          186.20      80.94   2.301    0.0253 *  \nprcp         -102.49      46.93  -2.184    0.0334 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2610 on 54 degrees of freedom\nMultiple R-squared:  0.1259,    Adjusted R-squared:  0.09356 \nF-statistic:  3.89 on 2 and 54 DF,  p-value: 0.0264\n\n\n\n\n2.1.1.2 Fines de semana lluviosos y templados\n\n\nCódigo\ndatosfilt &lt;- filter(datos,\n                    lluvia == \"Llueve\",\n                    tipo_dia == \"Fin de semana\",\n                    tavg &lt; 25)\n\nfitlm = lm(n ~ tavg + prcp, data = datosfilt)\nsummary(fitlm)\n\n\n\nCall:\nlm(formula = n ~ tavg + prcp, data = datosfilt)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1735.57  -607.12   -54.45   517.62  1882.70 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 3611.0469   908.5880   3.974 0.000691 ***\ntavg           0.0722    48.7403   0.001 0.998832    \nprcp         -64.1289    24.7465  -2.591 0.017032 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 904 on 21 degrees of freedom\nMultiple R-squared:  0.2635,    Adjusted R-squared:  0.1934 \nF-statistic: 3.757 on 2 and 21 DF,  p-value: 0.04028\n\n\n\n\n\n2.1.2 Predicción\nPara una primera evaluación de estos modelos, buscamos predecir la cantidad de usos del sistema Ecobici para un día de semana, con temperatura media de 24° y con un nivel de precipitaciones de 5 mm.\n\n\n\nNueva observación a predecir.\n\n\ntavg\nprcp\ntipo_dia\n\n\n\n\n24\n5\nLunes a viernes\n\n\n\n\n\n\n\nAjustamos diferentes modelos de acuerdo con la exploración inicial y vemos las predicciones y sus intervalos de confianza de nivel \\(95\\%\\).\n\n\nCódigo\ndatosfilt &lt;- filter(datos,\n                    lluvia == \"Llueve\",\n                    tipo_dia == \"Lunes a viernes\",\n                    tavg &lt; 25)\n\nm1 &lt;- lm(n ~ 1, data = datos)\nm2 &lt;- lm(n ~ 1, data = datosfilt)\nm3 &lt;- lm(n ~ tavg, data = datos)\nm4 &lt;- lm(n ~ tavg, data = datosfilt)\nm5 &lt;- lm(n ~ tavg + prcp, data = datos)\nm6 &lt;- lm(n ~ tavg + prcp, data = datosfilt)\n\npredichos &lt;- rbind(\n  predict(m1, nd, interval = \"prediction\"),\n  predict(m2, nd, interval = \"prediction\"),\n  predict(m3, nd, interval = \"prediction\"),\n  predict(m4, nd, interval = \"prediction\"),\n  predict(m5, nd, interval = \"prediction\"),\n  predict(m6, nd, interval = \"prediction\")\n)\n\npredichos &lt;- cbind(predichos, predichos[, 3] - predichos[, 2])\n\nrownames(predichos) &lt;- c(\n  \"Modelo 1: Todos los datos -&gt; mean(n)\",\n  \"Modelo 2: LaV, lluvia, &lt;25° -&gt; mean(n)\",\n  \"Modelo 3: Todos los datos -&gt; tavg\",\n  \"Modelo 4: LaV, lluvia, &lt;25° -&gt; tavg\",\n  \"Modelo 5: Todos los datos -&gt; tavg + prcp\",\n  \"Modelo 6: LaV, lluvia, &lt;25° -&gt; tavg + prcp\"\n)\n\ncolnames(predichos) &lt;- c(\"Pred\", \"linf\", \"lsup\", \"long\")\n\nknitr::kable(data.frame(predichos), caption = \"Predicciones con diferentes ajustes.\")\n\n\n\nPredicciones con diferentes ajustes.\n\n\n\nPred\nlinf\nlsup\nlong\n\n\n\n\nModelo 1: Todos los datos -&gt; mean(n)\n8020.412\n679.5616\n15361.26\n14681.70\n\n\nModelo 2: LaV, lluvia, &lt;25° -&gt; mean(n)\n9008.351\n3469.1432\n14547.56\n11078.42\n\n\nModelo 3: Todos los datos -&gt; tavg\n8408.683\n1075.0282\n15742.34\n14667.31\n\n\nModelo 4: LaV, lluvia, &lt;25° -&gt; tavg\n9844.809\n4300.5957\n15389.02\n11088.43\n\n\nModelo 5: Todos los datos -&gt; tavg + prcp\n8154.161\n897.8224\n15410.50\n14512.68\n\n\nModelo 6: LaV, lluvia, &lt;25° -&gt; tavg + prcp\n10333.054\n4948.6154\n15717.49\n10768.88\n\n\n\n\n\n\n\nComo es de esperar, el modelo que da lugar a un intervalo de predicción de menor longitud para esta nueva observación es el que incorpora datos de temperatura y precipitaciones, pero que fue construido con el dataset reducido a días de semana, templados y con lluvias."
  },
  {
    "objectID": "02_regresion_multiple.html#modelo-completo-temperatura-precipitaciones-y-tipo-de-día",
    "href": "02_regresion_multiple.html#modelo-completo-temperatura-precipitaciones-y-tipo-de-día",
    "title": "2  Regresión múltiple",
    "section": "2.2 Modelo completo: temperatura, precipitaciones y tipo de día",
    "text": "2.2 Modelo completo: temperatura, precipitaciones y tipo de día\nBuscamos un modelo más versátil y con buena capacidad predictiva. Para lo que sigue, transformamos la variable tipo_dia en una categórica (finde) representando por 1 a los días de fin de semana, y por 0, a los días de semana. Trabajamos con el dataset completo.\n\n\nCódigo\ndatos_tr &lt;- datos %&gt;%\n  mutate(finde = ifelse(tipo_dia == \"Lunes a viernes\", 0, 1)) %&gt;%\n  select(c(1, 2, 3, 6, 10))\n\nknitr::kable(datos_tr[1:10, ], caption = \"Datos con variable categórica para tipo de día, primeras 10 observaciones.\")\n\n\n\nDatos con variable categórica para tipo de día, primeras 10 observaciones.\n\n\nfecha\nn\ntavg\nprcp\nfinde\n\n\n\n\n2022-01-01\n2233\n24.8\n2.3\n1\n\n\n2022-01-02\n3162\n24.7\n1.5\n1\n\n\n2022-01-03\n7389\n27.9\n6.7\n0\n\n\n2022-01-04\n7215\n28.2\n3.9\n0\n\n\n2022-01-05\n7611\n21.7\n0.0\n0\n\n\n2022-01-06\n8336\n22.1\n0.0\n0\n\n\n2022-01-07\n8079\n23.8\n0.0\n0\n\n\n2022-01-08\n3529\n24.4\n0.0\n1\n\n\n2022-01-09\n3453\n24.9\n0.0\n1\n\n\n2022-01-10\n7825\n26.9\n0.0\n0\n\n\n\n\n\n\n\nEvaluamos un modelo que incorpora los datos de temperatura, precipitaciones y tipo de día a través de la variable categórica creada.\n\n\nCódigo\nfitlm = lm(n ~ poly(tavg, 2) + prcp + finde, data = datos_tr)\nsummary(fitlm)\n\n\n\nCall:\nlm(formula = n ~ poly(tavg, 2) + prcp + finde, data = datos_tr)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-7852.9  -882.7   159.1  1245.6  3643.8 \n\nCoefficients:\n                Estimate Std. Error t value             Pr(&gt;|t|)    \n(Intercept)     10137.43     125.46  80.803 &lt; 0.0000000000000002 ***\npoly(tavg, 2)1   7648.92    1967.85   3.887             0.000121 ***\npoly(tavg, 2)2 -18509.72    1940.26  -9.540 &lt; 0.0000000000000002 ***\nprcp             -123.97      20.57  -6.027        0.00000000417 ***\nfinde           -6614.07     224.73 -29.432 &lt; 0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1933 on 357 degrees of freedom\nMultiple R-squared:  0.734, Adjusted R-squared:  0.731 \nF-statistic: 246.2 on 4 and 357 DF,  p-value: &lt; 0.00000000000000022\n\n\nCódigo\ncoef &lt;- round(fitlm$coefficients, 0)\n\n\nLos coeficiente estimados sugieren que la cantidad basal de usos del sistema es de \\(10137\\) y que, ceteris paribus, ocurre lo siguiente:\n\ncomo la relación entre la cantidad de usos y la temperatura es modelada con un polinomio de grado 2 y con coeficientes \\(7649\\) y \\(-18510\\), para cada grado en la variable temperatura respectivamente, se penaliza la cantidad de usos por temperaturas extremas (comportamiento que ya habíamos comentado en el capítulo 1),\nlos usos disminuyen por la presencia de lluvia, a razón de \\(-124\\) por cada mm de precipitaciones registrado y,\nel mayor impacto en la cantidad de usos reside en el tipo de día, registrando una reducción de \\(6614\\) usos los fines de semana respecto de los días de semana.\n\n\n2.2.1 Predicción\nVolvemos a predecir la cantidad de usos del sistema Ecobici para un día de semana, con temperatura media de 24° y con un nivel de precipitaciones de 5 mm y comparamos con los predichos anteriores.\n\n\nCódigo\nnd &lt;- data.frame(tavg = 24, prcp = 5, finde = 0)\n\npredicho_nuevo &lt;- predict(fitlm, nd, interval = \"prediction\")\npredicho_nuevo &lt;-\n  cbind(predicho_nuevo, predicho_nuevo[, 3] - predicho_nuevo[, 2])\n\ncolnames(predicho_nuevo) &lt;- c(\"Pred\", \"linf\", \"lsup\", \"long\")\nrownames(predicho_nuevo) &lt;-\n  c(\"Modelo completo: Todos los datos -&gt; tavg + tavg^2 + prcp + finde\")\n\nknitr::kable(data.frame(rbind(predichos, predicho_nuevo)), caption = \"Predicciones con diferentes ajustes.\")\n\n\n\nPredicciones con diferentes ajustes.\n\n\n\nPred\nlinf\nlsup\nlong\n\n\n\n\nModelo 1: Todos los datos -&gt; mean(n)\n8020.412\n679.5616\n15361.26\n14681.700\n\n\nModelo 2: LaV, lluvia, &lt;25° -&gt; mean(n)\n9008.351\n3469.1432\n14547.56\n11078.415\n\n\nModelo 3: Todos los datos -&gt; tavg\n8408.683\n1075.0282\n15742.34\n14667.311\n\n\nModelo 4: LaV, lluvia, &lt;25° -&gt; tavg\n9844.809\n4300.5957\n15389.02\n11088.426\n\n\nModelo 5: Todos los datos -&gt; tavg + prcp\n8154.161\n897.8224\n15410.50\n14512.677\n\n\nModelo 6: LaV, lluvia, &lt;25° -&gt; tavg + prcp\n10333.054\n4948.6154\n15717.49\n10768.878\n\n\nModelo completo: Todos los datos -&gt; tavg + tavg^2 + prcp + finde\n9823.279\n6005.6077\n13640.95\n7635.343\n\n\n\n\n\n\n\nComo es de esperar, la predicción dada por el modelo completo parece ser más precisa que las de los restantes. Más aún, como el modelo estima a partir del conjunto de datos completo, su desempeño se mantiene, incluso para la predicción de la cantidad de usos del sistema Ecobici más generales, como por ejemplo, para un fin de semana, con temperatura media de 25°, sin lluvias, y en relación con los predichos anteriores.\n\n\nCódigo\nnd2 &lt;- data.frame(tavg = 20, prcp = 0, finde = 1)\n\nknitr::kable(nd2, caption = \"Otra nueva observación a predecir.\")\n\n\n\nOtra nueva observación a predecir.\n\n\ntavg\nprcp\nfinde\n\n\n\n\n20\n0\n1\n\n\n\n\n\n\n\n\n\nCódigo\npredicho_nuevo &lt;- predict(fitlm, nd2, interval = \"prediction\")\npredicho_nuevo &lt;-\n  cbind(predicho_nuevo, predicho_nuevo[, 3] - predicho_nuevo[, 2])\ncolnames(predicho_nuevo) &lt;- c(\"Pred\", \"linf\", \"lsup\", \"long\")\nrownames(predicho_nuevo) &lt;-\n  c(\"Modelo completo: Todos los datos -&gt; tavg + tavg^2 + prcp + finde\")\n\npredichos &lt;- rbind(\n  predict(m1, nd2, interval = \"prediction\"),\n  predict(m2, nd2, interval = \"prediction\"),\n  predict(m3, nd2, interval = \"prediction\"),\n  predict(m4, nd2, interval = \"prediction\"),\n  predict(m5, nd2, interval = \"prediction\"),\n  predict(m6, nd2, interval = \"prediction\")\n)\n\npredichos &lt;- cbind(predichos, predichos[, 3] - predichos[, 2])\n\nrownames(predichos) &lt;- c(\n  \"Modelo 1: Todos los datos -&gt; mean(n)\",\n  \"Modelo 2: LaV, lluvia, &lt;25° -&gt; mean(n)\",\n  \"Modelo 3: Todos los datos -&gt; tavg\",\n  \"Modelo 4: LaV, lluvia, &lt;25° -&gt; tavg\",\n  \"Modelo 5: Todos los datos -&gt; tavg + prcp\",\n  \"Modelo 6: LaV, lluvia, &lt;25° -&gt; tavg + prcp\"\n)\n\ncolnames(predichos) &lt;- c(\"Pred\", \"linf\", \"lsup\", \"long\")\n\nknitr::kable(data.frame(rbind(predichos, predicho_nuevo)), caption = \"Predicciones con diferentes ajustes.\")\n\n\n\nPredicciones con diferentes ajustes.\n\n\n\nPred\nlinf\nlsup\nlong\n\n\n\n\nModelo 1: Todos los datos -&gt; mean(n)\n8020.412\n679.5616\n15361.262\n14681.700\n\n\nModelo 2: LaV, lluvia, &lt;25° -&gt; mean(n)\n9008.351\n3469.1432\n14547.559\n11078.415\n\n\nModelo 3: Todos los datos -&gt; tavg\n8156.240\n834.1490\n15478.330\n14644.181\n\n\nModelo 4: LaV, lluvia, &lt;25° -&gt; tavg\n9307.742\n3842.4732\n14773.011\n10930.538\n\n\nModelo 5: Todos los datos -&gt; tavg + prcp\n8403.300\n1158.5107\n15648.090\n14489.579\n\n\nModelo 6: LaV, lluvia, &lt;25° -&gt; tavg + prcp\n10100.688\n4761.4766\n15439.899\n10678.422\n\n\nModelo completo: Todos los datos -&gt; tavg + tavg^2 + prcp + finde\n4555.102\n728.3893\n8381.814\n7653.425\n\n\n\n\n\n\n\nMientras todas las demás predicciones rondan valores entre \\(8000\\) y \\(10000\\), el modelo completo predice alrededor de \\(4300\\) usos, dando lugar, además, al intervalo de menor longitud observada. Es decir, el modelo de regresión múltiple que parece más adecuado para el problema es:\n\nn ~ tavg + tavg^2 + prcp + finde."
  },
  {
    "objectID": "02_regresion_multiple.html#sobre-el-dataset-de-clima",
    "href": "02_regresion_multiple.html#sobre-el-dataset-de-clima",
    "title": "2  Regresión múltiple",
    "section": "3.1 Sobre el dataset de clima",
    "text": "3.1 Sobre el dataset de clima\nLos datos de este ejemplo corresponden a datos de clima del año 2022 tomados de la base de datos meteorológicos y climáticos de MeteoStat (disponibles acá). En particular, se consideran los datos de la estación meteorológica de Aeroparque (ID 87582), desde el 1ro de enero de 2022 hasta el 31 de diciembre de 2022, y un conjunto reducido de variables.\n\n\nCódigo\nclima &lt;-\n  read_csv(\"./fuente/02_regresion_multiple/registro_tiempo_aeroparque.csv\") %&gt;%\n  select(c(1:5, 7:8, 10))"
  },
  {
    "objectID": "02_regresion_multiple.html#sobre-el-dataset-de-ecobici",
    "href": "02_regresion_multiple.html#sobre-el-dataset-de-ecobici",
    "title": "2  Regresión múltiple",
    "section": "3.2 Sobre el dataset de Ecobici",
    "text": "3.2 Sobre el dataset de Ecobici\nLos datos de este ejemplo corresponden a datos de uso del sistema Ecobici de la Ciudad de Buenos Aires (disponibles acá). En particular, se consideran los datos del año 2022 correspondientes a viajes de entre 5 minutos y 1 hora de duración.\nEcobici es el sistema de transporte público de bicicletas de la Ciudad de Buenos Aires, que tiene estaciones automáticas con bicicletas a disposición las 24 horas, todos los días del año. El sistema es gratuito para todas las personas residentes del país de lunes a viernes (días hábiles) con hasta cuatro viajes de 30 minutos cada uno. Sin embargo, si se utiliza por un tiempo mayor que el indicado o durante los fines de semana, existen diferentes pases con variados costos. A modo de referencia, el pase que habilita a hacer 6 viajes diarios de hasta 60 minutos cada uno cualquier día de la semana tiene un costo de $1.785 (junio 2023).\n\n\nCódigo\ntrips &lt;- read_csv(\n  \"./fuente/02_regresion_multiple/trips_2022.csv\",\n  col_types = cols(fecha_origen_recorrido = col_datetime(format = \"%Y-%m-%d %H:%M:%S\"))\n) %&gt;%\n  mutate(fecha = format(as_date(ymd_hms(\n    fecha_destino_recorrido\n  )))) %&gt;%\n  filter(duracion_recorrido &gt; 300 && duracion_recorrido &lt; 3600) %&gt;%\n  group_by(fecha) %&gt;%\n  count() %&gt;%\n  mutate(fecha = as_date(fecha))"
  },
  {
    "objectID": "02_regresion_multiple.html#dataset-pre-procesado-clima-bici.csv",
    "href": "02_regresion_multiple.html#dataset-pre-procesado-clima-bici.csv",
    "title": "2  Regresión múltiple",
    "section": "3.3 Dataset pre-procesado: clima-bici.csv",
    "text": "3.3 Dataset pre-procesado: clima-bici.csv\nPara reducir los datos al estudio de interés, se crea un dataset conjunto, clima-bici.csv, a partir de los datos de clima y de uso del sistema Ecobici, en el que se dispone de las siguientes variables.\n\nfecha: fecha, en el formato año-mes-día.\nn: cantidad de registros de uso del sistema EcoBici en la fecha indicada.\ntmed: temperatura media (°C) registrada en esa fecha.\ntmin: temperatura mínima (°C) registrada en esa fecha.\ntmax: temperatura máxima (°C) registrada en esa fecha.\nprcp: precipitaciones (mm) registrada en esa fecha.\ndia: día de la semana de la fecha indicada.\ntipo_dia: tipo de día (Fin de semana o Lunes a viernes) de la fecha indicada.\nlluvia: condición de lluvia (Llueve: prcp&gt;0, No llueve: prcp=0) de la fecha indicada.\n\n\n\nCódigo\ntrips &lt;- trips %&gt;%\n  filter(fecha &gt;= min(clima$date) & fecha &lt;= max(clima$date))\n\ndatos &lt;- left_join(trips, clima, by = c(\"fecha\" = \"date\")) %&gt;%\n  drop_na() %&gt;%\n  mutate(\n    dia = weekdays(fecha),\n    tipo_dia = ifelse(dia %in% c(\"sábado\", \"domingo\"), \"Fin de semana\", \"Lunes a viernes\"),\n    lluvia = ifelse(prcp == 0, \"No llueve\", \"Llueve\")\n  ) \n\n\nEl dataset también está disponible en la librería datosIC bajo el nombre de climabici.\n\n\nCódigo\ndevtools::install_github(\"daniellaparada/datosIC\")\nlibrary(datosIC)\ndata(climabici)\n\n\n\n\nCódigo\nknitr::kable(climabici[1:10,], caption = \"Dataset reducido disponible en la librería 'datosIC'.\")\n\n\n\nDataset reducido disponible en la librería 'datosIC'.\n\n\nfecha\nn\ntavg\ntmin\ntmax\nprcp\ndia\ntipo_dia\nlluvia\n\n\n\n\n2022-01-01\n2233\n24.8\n20.7\n29.1\n2.3\nsábado\nFin de semana\nLlueve\n\n\n2022-01-02\n3162\n24.7\n19.2\n29.7\n1.5\ndomingo\nFin de semana\nLlueve\n\n\n2022-01-03\n7389\n27.9\n24.1\n31.7\n6.7\nlunes\nLunes a viernes\nLlueve\n\n\n2022-01-04\n7215\n28.2\n24.8\n32.6\n3.9\nmartes\nLunes a viernes\nLlueve\n\n\n2022-01-05\n7611\n21.7\n16.7\n31.7\n0.0\nmiércoles\nLunes a viernes\nNo llueve\n\n\n2022-01-06\n8336\n22.1\n18.8\n25.7\n0.0\njueves\nLunes a viernes\nNo llueve\n\n\n2022-01-07\n8079\n23.8\n20.6\n26.6\n0.0\nviernes\nLunes a viernes\nNo llueve\n\n\n2022-01-08\n3529\n24.4\n21.8\n27.1\n0.0\nsábado\nFin de semana\nNo llueve\n\n\n2022-01-09\n3453\n24.9\n20.9\n29.5\n0.0\ndomingo\nFin de semana\nNo llueve\n\n\n2022-01-10\n7825\n26.9\n22.8\n31.3\n0.0\nlunes\nLunes a viernes\nNo llueve"
  },
  {
    "objectID": "03_test_hipotesis.html",
    "href": "03_test_hipotesis.html",
    "title": "3  Test de hipótesis",
    "section": "",
    "text": "4 Acerca de los datos\nA continuación, se detallan aspectos de los datasets que conformaron el dataset reducido para el desarrollo del ejemplo, a la vez que se incluyen las fuentes de los datos y el código utilizado para pre-procesarlo con la sintaxis de tidyverse. De esta forma, puede fácilmente replicarse y/o adaptarse si así se lo desea.\nTambién se incluye el enlace de descarga al dataset reducido, clima-flujo.csv, con el que se desarrolló el ejemplo.\nLas librerías usadas para el desarrollo de este ejemplo, así como la información de la sesión de R, se muestran en el código que sigue.\nCódigo\nrequire(ggplot2)\nrequire(tidyverse)\nrequire(ggfortify)\nrequire(plotly)\nrequire(vroom)\nrequire(effsize)\nrequire(ggmap)\nrequire(leaflet)\nrequire(devtools)\nCódigo\nsessionInfo()\n\n\nR version 4.2.3 (2023-03-15 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 22621)\n\nMatrix products: default\n\nlocale:\n[1] LC_COLLATE=Spanish_Argentina.utf8  LC_CTYPE=Spanish_Argentina.utf8   \n[3] LC_MONETARY=Spanish_Argentina.utf8 LC_NUMERIC=C                      \n[5] LC_TIME=Spanish_Argentina.utf8    \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] datosIC_0.0.0.9000 devtools_2.4.5     usethis_2.1.6      leaflet_2.1.2     \n [5] ggmap_3.0.2        effsize_0.8.1      vroom_1.6.1        plotly_4.10.1     \n [9] ggfortify_0.4.16   lubridate_1.9.2    forcats_1.0.0      stringr_1.5.0     \n[13] dplyr_1.1.2        purrr_1.0.1        readr_2.1.4        tidyr_1.3.0       \n[17] tibble_3.2.1       tidyverse_2.0.0    ggplot2_3.4.2     \n\nloaded via a namespace (and not attached):\n [1] bitops_1.0-7            fs_1.6.1                bit64_4.0.5            \n [4] RColorBrewer_1.1-3      httr_1.4.5              tools_4.2.3            \n [7] profvis_0.3.7           utf8_1.2.3              R6_2.5.1               \n[10] lazyeval_0.2.2          colorspace_2.1-0        urlchecker_1.0.1       \n[13] withr_2.5.0             sp_1.6-1                tidyselect_1.2.0       \n[16] gridExtra_2.3           prettyunits_1.1.1       processx_3.8.0         \n[19] curl_5.0.0              bit_4.0.5               compiler_4.2.3         \n[22] cli_3.6.1               labeling_0.4.2          scales_1.2.1           \n[25] callr_3.7.3             digest_0.6.31           rmarkdown_2.21         \n[28] jpeg_0.1-10             pkgconfig_2.0.3         htmltools_0.5.5        \n[31] sessioninfo_1.2.2       fastmap_1.1.1           htmlwidgets_1.6.2      \n[34] rlang_1.1.0             rstudioapi_0.14         shiny_1.7.4            \n[37] generics_0.1.3          farver_2.1.1            jsonlite_1.8.4         \n[40] crosstalk_1.2.0         magrittr_2.0.3          Rcpp_1.0.10            \n[43] munsell_0.5.0           fansi_1.0.4             lifecycle_1.0.3        \n[46] stringi_1.7.12          yaml_2.3.7              pkgbuild_1.4.0         \n[49] plyr_1.8.8              grid_4.2.3              parallel_4.2.3         \n[52] promises_1.2.0.1        crayon_1.5.2            miniUI_0.1.1.1         \n[55] lattice_0.21-8          hms_1.1.3               knitr_1.42             \n[58] ps_1.7.4                pillar_1.9.0            pkgload_1.3.2          \n[61] glue_1.6.2              evaluate_0.20           leaflet.providers_1.9.0\n[64] data.table_1.14.8       remotes_2.4.2           png_0.1-8              \n[67] vctrs_0.6.1             tzdb_0.3.0              httpuv_1.6.9           \n[70] RgoogleMaps_1.4.5.3     gtable_0.3.3            cachem_1.0.7           \n[73] xfun_0.39               mime_0.12               xtable_1.8-4           \n[76] later_1.3.0             viridisLite_0.4.2       memoise_2.0.1          \n[79] timechange_0.2.0        ellipsis_0.3.2"
  },
  {
    "objectID": "03_test_hipotesis.html#exploración-inicial",
    "href": "03_test_hipotesis.html#exploración-inicial",
    "title": "3  Test de hipótesis",
    "section": "3.1 Exploración inicial",
    "text": "3.1 Exploración inicial\nLos datos de flujo vehicular de la Ciudad de Buenos Aires reportan, por hora, la cantidad de vehículos registrados por radares ubicados en diferentes puntos de algunas autopistas de la ciudad.\nEn el siguiente mapa se muestra el total de flujo vehicular para cada uno de los radares durante 2019.\n\n\nCódigo\n# \"CartoDB.VoyagerLabelsUnder\"\nmapa19 &lt;- flujo19 %&gt;%\n  leaflet(options = leafletOptions(attributionControl = FALSE)) %&gt;%\n  addProviderTiles(\"CartoDB.VoyagerLabelsUnder\",\n                   options = providerTileOptions(opacity = 0.8)) %&gt;%\n  addCircleMarkers(\n    lng = ~ long,\n    lat = ~ lat,\n    fillOpacity = 0.9,\n    radius =  ~ 100 * n / (sum(n)),\n    weight = 1,\n    color = ~ paleta(n),\n    stroke = FALSE\n  )\nmapa19\n\n\n\n\n\n\nComo puede observarse en el mapa, el radar ubicado en la Autopista Lugones altura ESMA (RD 171), es el que mayor flujo registra para el año considerado. Los datos de 2023, que al momento de producir este documento solo se encuentran disponibles para el primer trimestre del año, exhiben una tendencia similar (a efectos creativos, se representan sobre un mapa en formato acuarelas: conocer más acá).\n\n\nCódigo\n# Radares\n# \"CartoDB.VoyagerLabelsUnder\"\nmapa23 &lt;- flujo23 %&gt;%\n  leaflet(options = leafletOptions(attributionControl = FALSE)) %&gt;%\n  addProviderTiles(\"Stamen.Watercolor\",\n                   options = providerTileOptions(opacity = 0.8)) %&gt;%\n  addCircleMarkers(\n    lng = ~ long,\n    lat = ~ lat,\n    fillOpacity = 0.9,\n    radius =  ~ 100 * n / (sum(n)),\n    weight = 1,\n    color = ~ paleta(n),\n    stroke = FALSE\n  )\nmapa23\n\n\n\n\n\n\nPara lo que sigue, trabajamos con el dataset reducido flujo-vehicular.csv en el que se incluyen datos del flujo vehicular de los días hábiles del primer trimestre de 2019 y de 2023 para el radar RD 171 ubicado en la Autopista Lugones, altura ESMA, sentido A.\nEl dataset flujo-vehicular.csv se encuentra acá. A continuación, se muestran 10 datos de dicho conjunto.\n\n\nCódigo\ndatos &lt;- read_csv(\"./fuente/03_test_hipotesis/flujo-vehicular.csv\")\n\n\n\n\n\nDataset reducido, primeras 10 observaciones.\n\n\nfecha\nn19\nn23\n\n\n\n\n01-02\n108550\n108794\n\n\n01-03\n118754\n114959\n\n\n01-04\n120250\n117394\n\n\n01-09\n49684\n118142\n\n\n01-10\n121533\n119916\n\n\n01-11\n123864\n120939\n\n\n01-16\n27560\n119623\n\n\n01-17\n121897\n118654\n\n\n01-18\n123497\n119748\n\n\n01-23\n121223\n118691\n\n\n\n\n\nCada observación corresponde al flujo total detectado por ese radar de un día que resultó hábil tanto en 2019 como en 2023. La elección de los años responde a lo siguiente: - los datos de 2020 y 2021 van a encontrarse influenciados por las restricciones de circulación de la pandemia de COVID-19 y la paulatina vuelta a la presencialidad, - los datos de 2022 no se encuentran disponibles para el año completo, sino para algunos meses al inicio y al fin del año.\nComo puede verse en el siguiente gráfico, existe una tendencia temporal que incide en el flujo vehicular del trimestre para ambos años.\n\n\n\n\n\n\nLas observaciones que se encuentran más alejadas de la recta identidad, corresponden a los días 20 y 21 de febrero de 2023, ambos feriados de carnaval, y a los días 9 y 16 de enero de 2019, ambos lunes, de posible retorno a la ciudad por recambio turístico. Removemos estas observaciones para lo que sigue.\n\n\n\n\n\n\nLos datos exhiben una estacionalidad que, naturalmente, afecta al usual supuesto de independencia: el flujo es creciente, para ambos años, a medida que transcurren los días durante el primer trimestre. Sumado a eso, el emparejamiento de los días por su simple correspondencia de fecha podría no ser comparable, salvo excepciones o hitos de cada año.\nPor ejemplo, la observación del 24 de enero de 2019 podría no ser comparable con la equivalente de 2023, aunque sí, quizás, con el de alguna fecha próxima a ella. Por la limitación de los datos disponibles para 2023, no es posible considerar otro tipo de agrupamientos. Sin embargo y pese a esto, el flujo vehicular registrado por ese radar parecer ser sistemáticamente menor en 2023 en relación con 2019."
  },
  {
    "objectID": "03_test_hipotesis.html#test-para-diferencia-de-medias-datos-apareados-primer-trimestre-2019-vs-2023",
    "href": "03_test_hipotesis.html#test-para-diferencia-de-medias-datos-apareados-primer-trimestre-2019-vs-2023",
    "title": "3  Test de hipótesis",
    "section": "3.2 Test para diferencia de medias (datos apareados: primer trimestre 2019 vs 2023)",
    "text": "3.2 Test para diferencia de medias (datos apareados: primer trimestre 2019 vs 2023)\nBajo ciertos reparos, puede ponerse a prueba la hipótesis anterior, asumiendo que algo de la estacionalidad observada puede resolverse apareando los datos. Más precisamente, un gráfico de las diferencias entre el flujo de 2019 y el de 2023 para los días considerados parece dar cuenta de tal efecto.\n\n\n\n\n\n\nParte de la estacionalidad parece haberse corregido y la media observada para las diferencias, que debería ser cercana a 0 en caso de no haber diferencias, se observa desplazada sugiriendo un flujo promedio mayor en 2019.\nRealizamos un test t para muestras apareadas a nivel \\(1\\%\\).\n\n\n\n\n\n\n\n\n    Paired t-test\n\ndata:  flujosout$n19 and flujosout$n23\nt = 4.9782, df = 27, p-value = 0.0000323\nalternative hypothesis: true mean difference is not equal to 0\n99 percent confidence interval:\n 1651.119 5795.881\nsample estimates:\nmean difference \n         3723.5 \n\n\n\nCohen's d\n\nd estimate: 0.4958838 (small)\n95 percent confidence interval:\n    lower     upper \n0.2842526 0.7075150 \n\n\nEn efecto, el \\(p-\\)valor es \\(0.0000323\\), y a partir de esta muestra y bajo las consideraciones ya mencionadas, rechazaríamos el supuesto de igualdad de flujos medios para ambos años, durante días hábiles del primer trimestre en ese radar. El tamaño del efecto parece ser moderado."
  },
  {
    "objectID": "03_test_hipotesis.html#incorporamos-datos-de-clima",
    "href": "03_test_hipotesis.html#incorporamos-datos-de-clima",
    "title": "3  Test de hipótesis",
    "section": "3.3 Incorporamos datos de clima",
    "text": "3.3 Incorporamos datos de clima\nPara lo que sigue, trabajamos con el dataset reducido flujo-clima.csv en el que se incluyen datos del flujo vehicular del primer trimestre de 2023 para el radar RD 171 ubicado en la Autopista Lugones, altura ESMA, sentido A, junto con datos de temperatura promedio y precipitaciones.\nEl dataset flujo-clima.csv se encuentra acá. A continuación, se muestran 10 datos de dicho conjunto.\nUn gráfico del flujo vehicular por tipo de día y según nivel de precipitaciones, parece mostrar lo esperado: el el flujo vehicular en ese punto de la ciudad es mayor los días de semana que los fines de semana. Sin embargo, no parece haber una tendencia notable que impacte en el flujo vehicular a partir de las precipitaciones. Dicha tendencia podría ser creciente, asumiendo que los días en que se registran mayores niveles de precipitaciones más personas utilizan el auto; o bien decreciente, sugiriendo que hay menor tránsito vehicular porque las personas prefieren suspender aquellas actividades fuera de sus hogares que no sean esenciales.\nAlgunas preguntas que pueden surgir a partir del gráfico son, por ejemplo:\n\n¿Hay diferencia en el flujo vehicular medio de los días de semana cuando llueve?\n¿Hay diferencia en el flujo vehicular medio de los días de semana cuando llueve?\n¿Hay diferencia en el flujo vehicular medio de los días miércoles respecto de los días viernes?\n\nSiempre, claro, recordando que estamos restringiendo el análisis al flujo vehicular detectado por el radar RD171, en la autopista Lugones, altura Esma.\nComo hicimos antes, para lo que sigue, descartamos las observaciones correspondientes a los días 20 y 21 de febrero y 24 de marzo, únicos feriados nacionales del trimestre.\nDel total de días hábiles, entonces, tenemos \\(19\\) observaciones que resultan de días de semana con lluvia, y \\(43\\) observaciones para días de semana sin lluvia.\n\n\nCódigo\n# Días de semana con lluvia: 19 datos\ndatos1 &lt;- flujoclima %&gt;%\n  filter(prcp &gt; 0,\n         tipo_dia == \"Lunes a viernes\")\n\n# Días de semana sin lluvia: 43 datos\ndatos2 &lt;- flujoclima %&gt;%\n  filter(prcp == 0,\n         tipo_dia == \"Lunes a viernes\")\n\nboxplot(\n  datos1$n,\n  datos2$n,\n  col = c(\"firebrick\", \"springgreen4\"),\n  names = c(\"Lluvia\", \"Sin lluvia\")\n)\n\n\n\n\n\nRealizamos un test t para diferencia de medias.\n\n\nCódigo\n# Test para diferencia de medias\nt.test(\n  x = datos1$n,\n  y = datos2$n,\n  alternative = \"two.sided\",\n  mu = 0,\n  paired = FALSE,\n  conf.level = 0.95\n)\n\n\n\n    Welch Two Sample t-test\n\ndata:  datos1$n and datos2$n\nt = 0.3956, df = 29.359, p-value = 0.6953\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -3883.205  5746.884\nsample estimates:\nmean of x mean of y \n 127948.4  127016.6 \n\n\nCódigo\ncohen.d(d = datos1$n, f = datos2$n, paired = FALSE)\n\n\n\nCohen's d\n\nd estimate: 0.1173876 (negligible)\n95 percent confidence interval:\n     lower      upper \n-0.4340511  0.6688262 \n\n\nCon un \\(p-\\)valor de \\(0.6953\\), no hay evidencia en la muestra para rechazar la hipótesis de igualdad de flujos medios. Es decir, a partir de la evidencia provista por la muestra, no es posible descartar que el flujo vehicular medio en días sin lluvia difiera del flujo medio cuando llueve.\nPodemos hacer otro test para ver si hay diferencia significativa para suponer que el flujo medio de los miércoles difiere del de los lunes. Las observaciones son menos, ya que en el primer trimestre solo se registran \\(13\\) miércoles y \\(12\\) viernes, considerando que se removió el 24 de marzo.\n\n\nCódigo\n# Días de semana con lluvia: 13 datos\ndatos1 &lt;- flujoclima %&gt;%\n  filter(dia == \"miércoles\")\n\n# Días de semana sin lluvia: 13 datos\ndatos2 &lt;- flujoclima %&gt;%\n  filter(dia == \"viernes\")\n\nboxplot(\n  datos1$n,\n  datos2$n,\n  col = c(\"firebrick\", \"springgreen4\"),\n  names = c(\"Miércoles\", \"Viernes\")\n)\n\n\n\n\n\n\n\nCódigo\nt.test(\n  x = datos1$n,\n  y = datos2$n,\n  alternative = \"two.sided\",\n  mu = 0,\n  paired = FALSE,\n  conf.level = 0.95\n)\n\n\n\n    Welch Two Sample t-test\n\ndata:  datos1$n and datos2$n\nt = -0.58982, df = 17.355, p-value = 0.5629\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -9601.871  5401.114\nsample estimates:\nmean of x mean of y \n 127669.5  129769.9 \n\n\nCódigo\ncohen.d(d = datos1$n, f = datos2$n, paired = FALSE)\n\n\n\nCohen's d\n\nd estimate: -0.2410676 (small)\n95 percent confidence interval:\n     lower      upper \n-1.0721910  0.5900558 \n\n\nNuevamente, y con un \\(p-\\)valor de \\(0.5629\\), concluimos que no hay evidencia en la muestra para rechazar la hipótesis de igualdad de flujos medios entre esos días, algo que al “ojo desnudo” podría parecer significativo. Ocurre, sin embargo, que la variabilidad exhibida en los flujos de los días viernes, parece ser mayor, como se observa en ambos gráficos previos. Una comparación que sí esperaría conducir a un rechazo de la igualdad de flujos medios podría ser la de miércoles y sábados.\n\n\nCódigo\n# Días de semana con lluvia: 13 datos\ndatos1 &lt;- flujoclima %&gt;%\n  filter(dia == \"miércoles\")\n\n# Días de semana sin lluvia: 13 datos\ndatos2 &lt;- flujoclima %&gt;%\n  filter(dia == \"sábado\")\n\nboxplot(\n  datos1$n,\n  datos2$n,\n  col = c(\"firebrick\", \"springgreen4\"),\n  names = c(\"Miércoles\", \"Sábado\")\n)\n\n\n\n\n\n\n\nCódigo\nt.test(\n  x = datos1$n,\n  y = datos2$n,\n  alternative = \"two.sided\",\n  mu = 0,\n  paired = FALSE,\n  conf.level = 0.95\n)\n\n\n\n    Welch Two Sample t-test\n\ndata:  datos1$n and datos2$n\nt = 6.9421, df = 18.759, p-value = 0.000001382\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 15757.64 29377.77\nsample estimates:\nmean of x mean of y \n 127669.5  105101.8 \n\n\nCódigo\ncohen.d(d = datos1$n, f = datos2$n, paired = FALSE)\n\n\n\nCohen's d\n\nd estimate: 2.82569 (large)\n95 percent confidence interval:\n   lower    upper \n1.655577 3.995802 \n\n\nEl test arroja un \\(p-\\)valor prácticamente nulo: podemos concluir que hay evidencia en la muestra para rechazar la hipótesis de igualdad de flujos medios entre los días miércoles y los días sábados. Además, el tamaño del efecto es grande."
  },
  {
    "objectID": "03_test_hipotesis.html#sobre-el-dataset-de-clima",
    "href": "03_test_hipotesis.html#sobre-el-dataset-de-clima",
    "title": "3  Test de hipótesis",
    "section": "4.1 Sobre el dataset de clima",
    "text": "4.1 Sobre el dataset de clima\nLos datos de este ejemplo corresponden a datos de clima del año 2023 tomados de la base de datos meteorológicos y climáticos de MeteoStat (disponibles acá). En particular, se consideran los datos de la estación meteorológica de Aeroparque (ID 87582) y un conjunto reducido de variables para el período considerado.\n\n\nCódigo\nclima &lt;-\n  read_csv(\"./fuente/03_test_hipotesis/registro_tiempo_aeroparque_2023.csv\") %&gt;%\n  select(c(1:5, 7:8, 10))"
  },
  {
    "objectID": "03_test_hipotesis.html#sobre-el-dataset-de-flujo-vehicular",
    "href": "03_test_hipotesis.html#sobre-el-dataset-de-flujo-vehicular",
    "title": "3  Test de hipótesis",
    "section": "4.2 Sobre el dataset de flujo vehicular",
    "text": "4.2 Sobre el dataset de flujo vehicular\nLos datos de este ejemplo corresponden a datos de flujo vehicular registrado en ciertos radares de AUSA, por hora, en la Ciudad de Buenos Aires para los años 2019 y 2023 (disponibles acá).\nAlgunas consideraciones, a la fecha, respecto de estos datos:\n\nLos datasets se encuentran disponibles para los años 2019 a 2023.\nNo todos tienen el mismo formato para el tratamiento de la fecha.\nLos datos de 2022 no están completos.\nLos datos de 2023 se encuentran disponibles al primer trimestre.\nLas coordenadas que georeferencian cada uno de los radares se encuentran “sucias” en los datos de 2023. En este capítulo se propuso una posible limpieza."
  },
  {
    "objectID": "03_test_hipotesis.html#dataset-pre-procesado-clima-flujo.csv",
    "href": "03_test_hipotesis.html#dataset-pre-procesado-clima-flujo.csv",
    "title": "3  Test de hipótesis",
    "section": "4.3 Dataset pre-procesado: clima-flujo.csv",
    "text": "4.3 Dataset pre-procesado: clima-flujo.csv\nPara reducir los datos al estudio de interés, se crea un dataset conjunto, clima-flujo.csv, a partir de los datos de flujo vehicular del primer trimestre de 2023 para el radar RD171 y de clima, en el que se dispone de las siguientes variables.\n\nfecha: fecha, en el formato mes-día.\nn: flujo vehicular de la fecha indicada.\ntavg: temperatura media (°C) registrada en esa fecha.\nprcp: precipitaciones (mm) registrada en esa fecha.\ndia: día de la semana de la fecha indicada.\ntipo_dia: tipo de día (Fin de semana o Lunes a viernes) de la fecha indicada.\n\nEl dataset también está disponible en la librería datosIC bajo el nombre de flujoclima.\n\n\nCódigo\ndevtools::install_github(\"daniellaparada/datosIC\")\nlibrary(datosIC)\ndata(flujoclima)\n\n\n\n\nCódigo\nknitr::kable(flujoclima[1:10,], caption = \"Dataset reducido disponible en la librería 'datosIC'.\")\n\n\n\nDataset reducido disponible en la librería ‘datosIC’.\n\n\nfecha\nn\ntavg\nprcp\ndia\ntipo_dia\n\n\n\n\n01-01\n74642\n22.8\n0.0\ndomingo\nFin de semana\n\n\n01-02\n108794\n22.7\n9.9\nlunes\nLunes a viernes\n\n\n01-03\n114959\n25.7\n0.0\nmartes\nLunes a viernes\n\n\n01-04\n117394\n23.8\n0.0\nmiércoles\nLunes a viernes\n\n\n01-05\n120350\n24.0\n0.0\njueves\nLunes a viernes\n\n\n01-06\n118283\n26.3\n0.0\nviernes\nLunes a viernes\n\n\n01-07\n94076\n26.1\n0.0\nsábado\nFin de semana\n\n\n01-08\n92560\n25.7\n0.0\ndomingo\nFin de semana\n\n\n01-09\n118142\n25.3\n0.0\nlunes\nLunes a viernes\n\n\n01-10\n119916\n25.4\n0.0\nmartes\nLunes a viernes"
  },
  {
    "objectID": "04_visualizacion.html",
    "href": "04_visualizacion.html",
    "title": "4  Visualización",
    "section": "",
    "text": "5 Acerca de los datos\nA continuación, se detallan aspectos de los datasets que conformaron el dataset reducido para el desarrollo del ejemplo, a la vez que se incluyen las fuentes de los datos y el código utilizado para pre-procesarlo con la sintaxis de tidyverse. De esta forma, puede fácilmente replicarse y/o adaptarse si así se lo desea.\nTambién se incluye el enlace de descarga al dataset reducido, sismos-arg.csv, con el que se desarrolló el ejemplo.\nLas librerías usadas para el desarrollo de este ejemplo, así como la información de la sesión de R, se muestran en el código que sigue.\nCódigo\nrequire(ggplot2)\nrequire(tidyverse)\nrequire(ggfortify)\nrequire(plotly)\nrequire(kableExtra)\nrequire(vroom)\nrequire(leaflet)\nrequire(lubridate)\nrequire(devtools)\nCódigo\nsessionInfo()\n\n\nR version 4.2.3 (2023-03-15 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 22621)\n\nMatrix products: default\n\nlocale:\n[1] LC_COLLATE=Spanish_Argentina.utf8  LC_CTYPE=Spanish_Argentina.utf8   \n[3] LC_MONETARY=Spanish_Argentina.utf8 LC_NUMERIC=C                      \n[5] LC_TIME=Spanish_Argentina.utf8    \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] datosIC_0.0.0.9000 devtools_2.4.5     usethis_2.1.6      leaflet_2.1.2     \n [5] vroom_1.6.1        kableExtra_1.3.4   plotly_4.10.1      ggfortify_0.4.16  \n [9] lubridate_1.9.2    forcats_1.0.0      stringr_1.5.0      dplyr_1.1.2       \n[13] purrr_1.0.1        readr_2.1.4        tidyr_1.3.0        tibble_3.2.1      \n[17] tidyverse_2.0.0    ggplot2_3.4.2     \n\nloaded via a namespace (and not attached):\n [1] httr_1.4.5              pkgload_1.3.2           bit64_4.0.5            \n [4] jsonlite_1.8.4          viridisLite_0.4.2       shiny_1.7.4            \n [7] highr_0.10              yaml_2.3.7              remotes_2.4.2          \n[10] sessioninfo_1.2.2       pillar_1.9.0            glue_1.6.2             \n[13] digest_0.6.31           promises_1.2.0.1        rvest_1.0.3            \n[16] leaflet.providers_1.9.0 colorspace_2.1-0        htmltools_0.5.5        \n[19] httpuv_1.6.9            pkgconfig_2.0.3         xtable_1.8-4           \n[22] scales_1.2.1            webshot_0.5.4           processx_3.8.0         \n[25] svglite_2.1.1           later_1.3.0             tzdb_0.3.0             \n[28] timechange_0.2.0        farver_2.1.1            generics_0.1.3         \n[31] ellipsis_0.3.2          cachem_1.0.7            withr_2.5.0            \n[34] lazyeval_0.2.2          cli_3.6.1               magrittr_2.0.3         \n[37] crayon_1.5.2            mime_0.12               memoise_2.0.1          \n[40] evaluate_0.20           ps_1.7.4                fs_1.6.1               \n[43] fansi_1.0.4             xml2_1.3.3              pkgbuild_1.4.0         \n[46] profvis_0.3.7           tools_4.2.3             data.table_1.14.8      \n[49] prettyunits_1.1.1       hms_1.1.3               lifecycle_1.0.3        \n[52] munsell_0.5.0           callr_3.7.3             compiler_4.2.3         \n[55] systemfonts_1.0.4       rlang_1.1.0             grid_4.2.3             \n[58] rstudioapi_0.14         htmlwidgets_1.6.2       crosstalk_1.2.0        \n[61] miniUI_0.1.1.1          labeling_0.4.2          rmarkdown_2.21         \n[64] gtable_0.3.3            curl_5.0.0              R6_2.5.1               \n[67] gridExtra_2.3           knitr_1.42              fastmap_1.1.1          \n[70] bit_4.0.5               utf8_1.2.3              stringi_1.7.12         \n[73] Rcpp_1.0.10             vctrs_0.6.1             urlchecker_1.0.1       \n[76] tidyselect_1.2.0        xfun_0.39"
  },
  {
    "objectID": "04_visualizacion.html#exploración-inicial",
    "href": "04_visualizacion.html#exploración-inicial",
    "title": "4  Visualización",
    "section": "4.1 Exploración inicial",
    "text": "4.1 Exploración inicial\nLos datos de sismos pueden obtenerse del buscador disponible en el INPRES, acá, en el que se registran eventos sísmicos en territorio argentino y diferentes variables asociadas a estos, en particular, si se trata de un sismo que se haya sentido o no.\nPara lo que sigue, trabajamos con el dataset reducido sismos-arg.csv en el que se incluyen datos de sismos de diferente intensidad y magnitud en la región continental del país (excluyendo Tierra del Fuego) desde el 7 de enero de 2012, hasta el 18 de mayo de 2022.\nEl dataset sismos-arg.csv se encuentra acá y ha sido transformado a partir de datos scrappeados del buscador de sismos del INPRES, cortesía de Gustavo Juantorena. A continuación, se muestran 10 datos de dicho conjunto.\n\n\nCódigo\n#datos &lt;- read_csv(\"./fuente/04_visualizacion/sismos-arg.csv\")\n\ndevtools::install_github(\"daniellaparada/datosIC\")\nlibrary(datosIC)\ndata(sismos)\n\ndatos &lt;- sismos\n\n\n\n\n\nDataset reducido\n\n\nFecha\nHora\nLatitud\nLongitud\nProvincia\nPercibido\nMagnitud\nProfundidad\n\n\n\n\n2022-05-18\n13:09:56\n-31.820\n-67.040\nSan Juan\nFALSE\n3.0\n134\n\n\n2022-05-18\n10:18:34\n-24.216\n-67.139\nSalta\nFALSE\n3.2\n185\n\n\n2022-05-18\n09:40:09\n-31.262\n-68.708\nSan Juan\nFALSE\n3.3\n104\n\n\n2022-05-18\n09:25:43\n-32.521\n-70.085\nSan Juan\nFALSE\n2.7\n112\n\n\n2022-05-18\n08:45:59\n-28.192\n-67.376\nCatamarca\nFALSE\n2.7\n142\n\n\n2022-05-18\n08:42:33\n-32.043\n-70.030\nSan Juan\nFALSE\n2.7\n114\n\n\n2022-05-17\n23:22:48\n-23.442\n-66.846\nJujuy\nFALSE\n3.6\n210\n\n\n2022-05-17\n21:21:18\n-23.503\n-66.831\nJujuy\nFALSE\n3.6\n210\n\n\n2022-05-17\n17:17:58\n-22.794\n-66.228\nJujuy\nFALSE\n4.0\n273\n\n\n2022-05-17\n14:46:04\n-31.505\n-68.640\nSan Juan\nFALSE\n2.7\n103\n\n\n\n\n\n\n\nLa variable ´Percibido´ es la que registra si la intensidad del sismo fue percibida, o no, por la población del territorio afectado. Los sismos son más frecuentes de lo que, quizás, supongamos. El siguiente mapa ofrece una posible visualización para los sismos percibidos y no percibidos de los últimos 10 años. Dentro del mapa, es posible activar la capa topográfica para relacionar, por ejemplo, los sismos con el relieve del territorio.\n\n\nCódigo\nsismos_arg &lt;- datos\npal1 &lt;-\n  colorNumeric(palette = c(\"deeppink2\", \"deeppink4\"),\n               domain = sismos_arg$Profundidad)\npal2 &lt;-\n  colorNumeric(palette = c(\"dodgerblue2\", \"dodgerblue4\"),\n               domain = sismos_arg$Profundidad)\n\nmapa_arg &lt;- sismos_arg %&gt;%\n  leaflet(options = leafletOptions(attributionControl = FALSE)) %&gt;%\n  addTiles(group = \"OSM (default)\") %&gt;%\n  addProviderTiles(\"OpenTopoMap\",\n                   group = \"Topográfico\",\n                   options = providerTileOptions(opacity = 0.5)) %&gt;%\n  addCircleMarkers(\n    data = sismos_arg %&gt;%\n      filter(Percibido == FALSE),\n    lng = ~ Longitud,\n    lat = ~ Latitud,\n    fillOpacity = 0.15,\n    radius =  ~ Magnitud,\n    color = ~ pal2(Profundidad),\n    stroke = FALSE,\n    group = \"Sismos no percibidos\"\n  ) %&gt;%\n  addCircleMarkers(\n    data = sismos_arg %&gt;%\n      filter(Percibido == TRUE),\n    lng = ~ Longitud,\n    lat = ~ Latitud,\n    fillOpacity = 0.15,\n    radius =  ~ Magnitud,\n    color = ~ pal1(Profundidad),\n    stroke = FALSE,\n    group = \"Sismos percibidos\"\n  ) %&gt;%\n  addLayersControl(\n    baseGroups = c(\"OSM (default)\", \"Topográfico\"),\n    overlayGroups = c(\"Sismos no percibidos\", \"Sismos percibidos\"),\n    options = layersControlOptions(collapsed = TRUE)\n  )\n\nmapa_arg\n\n\n\n\n\n\nEl radio de cada punto indica la magnitud del sismo, mientras que la intensidad del color, su profundidad. Los sismos también se clasifican de acuerdo con la profundidad de su foco: desde la corteza terreste y hasta 70 km de profundidad, son superficiales; entre los 70 y los 450 km de profundidad, son intermedios; y para más de 450 km profundidad, profundos. Los más profundos, en el mapa, se ubican en la capa de sismos no percibidos (azul) sobre la falla que recorre en línea más o menos vertical las provincias de Salta y Santiago del Estero. Profundidades intermedias se encuentran, mayoritariamente, en el oeste de Jujuy. El resto, en general, corresponde a profundidades superficiales.\nLas provincias de San Juan, Salta, Jujuy, La Rioja, Mendoza, Catamarca, y Córdoba son aquellas que registran más de 1000 eventos durante el período observado. El siguiente mapa ofrece una visualización de sismos para dichas provincias, indicando con color su magnitud.\n\n\nCódigo\ntop &lt;-\n  c(\"San Juan\",\n    \"Salta\",\n    \"Jujuy\",\n    \"La Rioja\",\n    \"Mendoza\",\n    \"Catamarca\",\n    \"Córdoba\")\npal3 &lt;-\n  colorNumeric(\n    palette = c(\"gold\", \"sienna1\", \"firebrick\", \"darkred\", \"orangered4\"),\n    domain = sismos_arg$Magnitud\n  )\n\nmapa_arg_top &lt;- sismos_arg %&gt;%\n  leaflet(options = leafletOptions(attributionControl = FALSE)) %&gt;%\n  addTiles(group = \"OSM (default)\") %&gt;%\n  addProviderTiles(\"OpenTopoMap\",\n                   group = \"Topográfico\",\n                   options = providerTileOptions(opacity = 0.5)) %&gt;%\n  addCircles(\n    data = sismos_arg %&gt;%\n      filter(Provincia == top[1]),\n    lng = ~ Longitud,\n    lat = ~ Latitud,\n    fillOpacity = 1,\n    color =  ~ pal3(Magnitud),\n    stroke = FALSE,\n    group = top[1]\n  ) %&gt;%\n  addCircles(\n    data = sismos_arg %&gt;%\n      filter(Provincia == top[2]),\n    lng = ~ Longitud,\n    lat = ~ Latitud,\n    fillOpacity = 1,\n    color =  ~ pal3(Magnitud),\n    stroke = FALSE,\n    group = top[2]\n  ) %&gt;%\n  addCircles(\n    data = sismos_arg %&gt;%\n      filter(Provincia == top[3]),\n    lng = ~ Longitud,\n    lat = ~ Latitud,\n    fillOpacity = 1,\n    color =  ~ pal3(Magnitud),\n    stroke = FALSE,\n    group = top[3]\n  ) %&gt;%\n  addCircles(\n    data = sismos_arg %&gt;%\n      filter(Provincia == top[4]),\n    lng = ~ Longitud,\n    lat = ~ Latitud,\n    fillOpacity = 1,\n    color =  ~ pal3(Magnitud),\n    stroke = FALSE,\n    group = top[4]\n  ) %&gt;%\n  addCircles(\n    data = sismos_arg %&gt;%\n      filter(Provincia == top[5]),\n    lng = ~ Longitud,\n    lat = ~ Latitud,\n    fillOpacity = 1,\n    color =  ~ pal3(Magnitud),\n    stroke = FALSE,\n    group = top[5]\n  ) %&gt;%\n  addCircles(\n    data = sismos_arg %&gt;%\n      filter(Provincia == top[6]),\n    lng = ~ Longitud,\n    lat = ~ Latitud,\n    fillOpacity = 1,\n    color =  ~ pal3(Magnitud),\n    stroke = FALSE,\n    group = top[6]\n  ) %&gt;%\n  addCircles(\n    data = sismos_arg %&gt;%\n      filter(Provincia == top[7]),\n    lng = ~ Longitud,\n    lat = ~ Latitud,\n    fillOpacity = 1,\n    color =  ~ pal3(Magnitud),\n    stroke = FALSE,\n    group = top[7]\n  ) %&gt;%\n  addLayersControl(\n    baseGroups = c(\"OSM (default)\", \"Topográfico\"),\n    overlayGroups = top,\n    options = layersControlOptions(collapsed = TRUE)\n  )\nmapa_arg_top\n\n\n\n\n\n\nLa percepción del sismo por parte de la población no está únicamente asociada a la magnitud y/o profundidad. Por ejemplo, un sismo de magnitud 2.6 y profundidad de 7 km en Córdoba es percibido, mientras que otro, de magnitud 2.7 y profundidad de 12 km en Catamarca no es percibido. Lo mismo ocurre para magnitudes y/o profundidades mayores. El siguiente mapa ofrece una visualización similar al anterior, pero restringido únicamente a los sismos percibidos del conjunto de datos.\n\n\nCódigo\nmapa_arg_top_perc &lt;- sismos_arg %&gt;%\n  leaflet(options = leafletOptions(attributionControl = FALSE)) %&gt;%\n  addTiles(group = \"OSM (default)\") %&gt;%\n  addProviderTiles(\"OpenTopoMap\",\n                   group = \"Topográfico\",\n                   options = providerTileOptions(opacity = 0.5)) %&gt;%\n  addCircles(\n    data = sismos_arg %&gt;%\n      filter(Provincia == top[1],\n             Percibido == TRUE),\n    lng = ~ Longitud,\n    lat = ~ Latitud,\n    fillOpacity = 1,\n    color =  ~ pal3(Magnitud),\n    stroke = FALSE,\n    group = top[1]\n  ) %&gt;%\n  addCircles(\n    data = sismos_arg %&gt;%\n      filter(Provincia == top[2],\n             Percibido == TRUE),\n    lng = ~ Longitud,\n    lat = ~ Latitud,\n    fillOpacity = 1,\n    color =  ~ pal3(Magnitud),\n    stroke = FALSE,\n    group = top[2]\n  ) %&gt;%\n  addCircles(\n    data = sismos_arg %&gt;%\n      filter(Provincia == top[3],\n             Percibido == TRUE),\n    lng = ~ Longitud,\n    lat = ~ Latitud,\n    fillOpacity = 1,\n    color =  ~ pal3(Magnitud),\n    stroke = FALSE,\n    group = top[3]\n  ) %&gt;%\n  addCircles(\n    data = sismos_arg %&gt;%\n      filter(Provincia == top[4],\n             Percibido == TRUE),\n    lng = ~ Longitud,\n    lat = ~ Latitud,\n    fillOpacity = 1,\n    color =  ~ pal3(Magnitud),\n    stroke = FALSE,\n    group = top[4]\n  ) %&gt;%\n  addCircles(\n    data = sismos_arg %&gt;%\n      filter(Provincia == top[5],\n             Percibido == TRUE),\n    lng = ~ Longitud,\n    lat = ~ Latitud,\n    fillOpacity = 1,\n    color =  ~ pal3(Magnitud),\n    stroke = FALSE,\n    group = top[5]\n  ) %&gt;%\n  addCircles(\n    data = sismos_arg %&gt;%\n      filter(Provincia == top[6],\n             Percibido == TRUE),\n    lng = ~ Longitud,\n    lat = ~ Latitud,\n    fillOpacity = 1,\n    color =  ~ pal3(Magnitud),\n    stroke = FALSE,\n    group = top[6]\n  ) %&gt;%\n  addCircles(\n    data = sismos_arg %&gt;%\n      filter(Provincia == top[7],\n             Percibido == TRUE),\n    lng = ~ Longitud,\n    lat = ~ Latitud,\n    fillOpacity = 1,\n    color =  ~ pal3(Magnitud),\n    stroke = FALSE,\n    group = top[7]\n  ) %&gt;%\n  addLayersControl(\n    baseGroups = c(\"OSM (default)\", \"Topográfico\"),\n    overlayGroups = top,\n    options = layersControlOptions(collapsed = TRUE)\n  )\nmapa_arg_top_perc\n\n\n\n\n\n\nAllí puede verse que, mientras que en San Juan los sismos percibidos parecen ser de magnitudes altas, en Córdoba ocurre lo contrario.\nPor otro lado, la profundidad de los sismos guarda estrecha relación con la configuración geológica y tecnótica de su ubicación geográfica. El gráfico que sigue toma los eventos de las provincias con más registros y exhibe la relación entre la profundidad del sismo y los paralelos de su ubicación de registro. Llamativo resulta ver que la actividad sísmica disminuye en las profundidades que separan los sismos superficiales de los intermedios. Como veíamos, las mayores profundidades se detectan en las provincias de Salta y Jujuy, con la excepción de una pequeña región entre paralelos en San Juan.\n\n\n\n\n\n\nConocimiento sobre la configuración tectónica permite interpretaciones más profundas. Por ejemplo, la zona norte de Mendoza ubicada entre los paralelos -32.5 y -33.5 y donde se ubica parte del Gran Mendoza, se encuentra en la región de mayor peligrosidad sísmica según INPRES. Lo que ocurre es que allí se da la convergencia entre la placa Sudamericana y la placa de Nazca, que se extiende a lo largo de la fosa Peruano-Chilena y en su movimiento en la dirección Este, subduce debajo de la Sudamericana, que se mueve en sentido opuesto. Dicho mecanismo induce un régimen de esfuerzos compresionales a la placa Sudamericana y que resultan responsables de la orientación y sentido del desplazamiento de las fallas lo que, como consecuencia, caracteriza la sismicidad de la zona.\nEl siguiente gráfico muestra la profundidad en relación con la longitud de la ubicación del foco para la zona norte de Mendoza ubicada entre los paralelos -32.5° y -33.5°, zona de subducción entre la placa de Nazca y la Sudamericana (zona de Benioff). Un análisis experto puede halar en el gráfico evidencia de la placa de Nazca subducida y moviéndose en dirección Este respecto a la placa Sudamericana (más detalle sobre esto puede consultarse acá).\n\n\n\n\n\n\nLa tabla que sigue resume, por provincia, la cantidad de sismos registrados, los percibidos, así como la magnitud y profundidad mediana. De las provincias con mayor cantidad de eventos registrados, Jujuy y Salta registran los sismos más profundos, mientras que Córdoba registra sismos superficiales, con una intensidad mediana de 2.8, y es de las provincias con mayor tasa de sismos percibidos de entre las de mayor cantidad de eventos registrados. San Juan registra muchos sismos, más de la mitad de ellos de profundidad media a profunda, pero con una tasa de percepción relativamente baja, como Salta y Jujuy.\n\n\nCódigo\nknitr::kable(sismos_prov, caption = \"Resumen por provincias\")\n\n\n\nResumen por provincias\n\n\nProvincia\nn\nnperc\nMagmed\nProfmed\n\n\n\n\nBuenos Aires\n7\n5\n3.7\n31\n\n\nCatamarca\n3317\n109\n2.8\n139\n\n\nChaco\n3\n0\n3.3\n231\n\n\nChubut\n1\n0\n3.8\n169\n\n\nCorrientes\n2\n0\n3.7\n267\n\n\nCórdoba\n1145\n313\n2.8\n21\n\n\nEntre Ríos\n1\n0\n3.8\n32\n\n\nFormosa\n3\n0\n3.8\n342\n\n\nJujuy\n5270\n64\n3.2\n223\n\n\nLa Pampa\n5\n4\n3.6\n22\n\n\nLa Rioja\n4616\n166\n2.8\n114\n\n\nMendoza\n4319\n303\n2.7\n31\n\n\nNeuquén\n231\n66\n3.0\n8\n\n\nRío Negro\n1\n0\n2.9\n98\n\n\nSalta\n5781\n61\n3.2\n195\n\n\nSan Juan\n29920\n619\n2.7\n106\n\n\nSan Luis\n568\n69\n2.8\n22\n\n\nSanta Cruz\n46\n22\n3.0\n14\n\n\nSantiago del Estero\n255\n59\n3.2\n30\n\n\nTucumán\n326\n46\n2.8\n27\n\n\n\n\n\n\n\n\n\nCódigo\nknitr::kable(sismos_prov_porc, caption = \"Porcentaje de sismos percibidos para casos de más de 1000 eventos\")\n\n\n\nPorcentaje de sismos percibidos para casos de más de 1000 eventos\n\n\nProvincia\npperc\n\n\n\n\nCatamarca\n3.286102\n\n\nCórdoba\n27.336244\n\n\nJujuy\n1.214421\n\n\nLa Rioja\n3.596187\n\n\nMendoza\n7.015513\n\n\nSalta\n1.055181\n\n\nSan Juan\n2.068850"
  },
  {
    "objectID": "04_visualizacion.html#análisis-para-el-caso-de-san-juan",
    "href": "04_visualizacion.html#análisis-para-el-caso-de-san-juan",
    "title": "4  Visualización",
    "section": "4.2 Análisis para el caso de San Juan",
    "text": "4.2 Análisis para el caso de San Juan\nSan Juan registra casi 30.000 eventos para el período considerado de poco más de 10 años, con una mediana de 8 sismos diarios. Un histograma para la cantidad diaria de sismos se observa a continuación.\n\n\n\n\n\n\nEn el histograma puede verse que hay por lo menos una observación que supera los 100 sismos diarios. En efecto, se trata del terremoto del 18 de enero de 2021 en La Rinconada, San Juan, en el que se reportaron colapsos de viviendas de adobe, grietas distensivas a lo largo del eje de la Ruta Nacional 40, derrumbes parciales, y otros daños serios principalmente en los Departamentos de Pocito y Sarmiento. Durante las 72 hs posteriores al terremoto de magnitud 6.4, se registraron más de 150 réplicas de magnitudes entre 2.5 y 5.3. Más información acá.\nEl siguiente gráfico muestra la cantidad de sismos diarios. Puede apreciarse las réplicas de tal terremoto en las observaciones que corresponden a los días entre el 19 y el 23 de enero de 2021.\n\n\n\n\n\n\nComo vimos, San Juan registra más de 600 sismos percibidos durante el período, algo más que el 2% del total de sismos registrados. La frecuencia con la que se perciben tales sismos es alta. Eso puede observarse en el histograma para la cantidad de días transcurridos entre un sismo percibido y otro.\n\n\n\n\n\n\nCórdoba y Mendoza, registrando cerca del 27% y 7% de sismos percibidos respecto del total, respectivamente, tienen una frecuencia ligeramente más espaciada que la de San Juan.\n\n\n\n\n\n\n\n\n\n\n\n4.2.1 Gutenberg-Richter\nLa ley de Gutenberg-Richter es una fórmula que permite cuantificar la relación entre la frecuencia y la magnitud de la actividad sísmica de una región. La relación fue inicialmente propuesta por Charles Francis Richter y Beno Gutenberg hace más de 70 años y es aun objeto de caracterización de sismos, pues se ha mostrado relativamente invariante por región y en el tiempo.\nN es un número de sismos de magnitud mayor que M durante un período de tiempo “t”, logN es un logaritmo del número de sismos con magnitud M La ley establece que la recurrencia sísmica de magnitud mayor o igual a \\(M\\) durante un período de tiempo \\(t\\), en una región, se relaciona con la cantidad de sismos, \\(N\\), de magnitud mayor que \\(M\\) durante el período, a través de\n\\[\n\\log _{10} N=a-b M,\n\\]\ndonde \\(a\\) y \\(b\\) son constantes determinadas por la naturaleza sísmica de la región, en general, a partir de datos históricos.\nAjustamos los datos de San Juan al modelo de Gutenberg-Richter para estimar las constantes \\(a\\) y \\(b\\). En el siguiente gráfico puede verse la cantidad \\(N\\) de sismos de magnitud mayor que \\(M\\) por año (escala logarítmica en base 10). Como los años 2012 y 2022 no están completos para el año calendario, reducimos los datos al período 2013-2021.\n\n\n\n\n\n\nLa estimación por mínimos cuadrados de \\(a\\) y de \\(b\\) puede verse a continuación.\nLos coeficientes estimados son \\(6.1812\\) para \\(a\\), y \\(1.1433\\) para \\(b\\). El coeficiente \\(b\\) suele ser aproximadamente igual a \\(1\\) para sismos tectónicos. Como los datos con los que se estimó son de frecuencia anual, la cantidad \\(a/b\\) puede interpretarse como, en promedio y una vez al año, la ocurrencia de un terremoto de magnitud \\(a/b\\) o superior. En este caso, \\(a/b=5.4065\\), lo que sugiere que, en promedio, una vez al año se registra en San Juan un terremoto de magnitud aproximada \\(5.4\\) o superior.\nEn el siguiente gráfico se superpone, en azul, la curva estimada de Gutenberg-Richter\n\\[\n\\log _{10} N=6.1812-1.1433 M,\n\\]\na partir de los datos de San Juan.\n\n\n\n\n\n\n\n\n4.2.2 Estimación de la probabiblidad de ocurrencia de futuros sismos\nDel análisis de los resultados de la tasa o frecuencia media de ocurrencia por unidad de tiempo, suele derivarse la estimación de la probabilidad de ocurrencia de futuros eventos sísmicos en la región estudiada, bajo el supuesto fundamental de que el nivel de actividad sísmica de los últimos años se mantendrá aproximadamente igual, en promedio, para los próximos años.\nPara evaluar dicho riesgo sísmico, se modela la probabilidad con una distribución de Poisson, pues se supone que los eventos sísmicos se producen de un modo aleatorio e independiente, donde los tiempos de origen, las coordenadas de los focos y las magnitudes son variables independientes entre sí. Es decir, que la ocurrencia de un evento sísmico no tiene influencia en la ocurrencia de otro, y que la probabilidad de que dos eventos sucedan en el mismo sitio y al mismo tiempo es casi nula.\nEn general, tales hipótesis no concuerdan completamente con la naturaleza física de la acumulación de energía en zonas sísmicas. Sin embargo, y a pesar de estas limitaciones, este modelo provee una medida del riesgo sísmico relativamente sencilla, interpretable y típicamente usada por la comunidad experta para proveer una cuantificación de riesgo aceptable para las regiones.\nEntonces, bajo este modelo, la probabilidad de ocurrencia de al menos un sismo de magnitud mayor que \\(M\\) en los próximos \\(t\\) años se calcula como \\[\nP(t)=1-e^{-N_1(M) \\times t} .\n\\] donde \\(N_1(M)=10^{(a-b M \\log t)}\\). Luego, el número promedio de años para que un sismo de magnitud mayor que \\(M\\) ocurra está dado por \\[\nT_R=\\frac{1}{N_1(M)}.\n\\] Tomando como referencia la estimación de \\(a\\) y \\(b\\) obtenida para San Juan, la estimación de la probabilidad de ocurrencia de al menos un sismo de magnitud mayor que \\(M\\) en San Juan en los próximos \\(t\\) años, para \\(t\\in\\{1,5,10,20\\}\\), se observa en el siguiente gráfico.\n\n\n\n\n\n\nAsí, por ejemplo, la probabilidad estimada de que un sismo de magnitud superior a 6 ocurra en San Juan ocurra en los próximos 5 años es de casi \\(0.65\\), aumenta a \\(0.88\\) para los próximos 10 años y es de casi \\(1\\) para los próximos 20. En efecto, los únicos sismos registrados en los datos de tal magnitud son los de noviembre de 2016 y enero de 2021. Sismos de magnitud superior a 4.5 en San Juan son casi seguros para los próximos años, en todos los casos.\n\n\nCódigo\nknitr::kable(sismos_SJ %&gt;%\n  filter(Magnitud &gt; 6), caption = \"Sismos de magnitud superior a 6 en San Juan, desde 2013 a 2021\")\n\n\n\nSismos de magnitud superior a 6 en San Juan, desde 2013 a 2021\n\n\nFecha\nHora\nLatitud\nLongitud\nProvincia\nPercibido\nMagnitud\nProfundidad\nFechaHora\nAño\n\n\n\n\n2016-11-20\n17:57:44\n-31.630\n-68.663\nSan Juan\nTRUE\n6.3\n107\n2016-11-20 17:57:44\n2016\n\n\n2021-01-18\n23:46:20\n-31.854\n-68.963\nSan Juan\nTRUE\n6.4\n8\n2021-01-18 23:46:20\n2021"
  },
  {
    "objectID": "04_visualizacion.html#sobre-el-dataset-de-sismos",
    "href": "04_visualizacion.html#sobre-el-dataset-de-sismos",
    "title": "4  Visualización",
    "section": "5.1 Sobre el dataset de sismos",
    "text": "5.1 Sobre el dataset de sismos\nLos datos de este ejemplo corresponden a datos scrappeados del buscador de sismos del INPRES, cuyo buscador está disponible acá. En el dataset sismos_all.csv, disponible acá, en el que se registran eventos sísmicos en territorio argentino y diferentes variables asociadas a estos, en particular, si se trata de un sismo que se haya sentido o no.\nLos sismos registrados en INPRES pueden estar revisados por un sismólogo y, posiblemente a razón de ello, algunas inconsistencias en la nomenclatura de las provincias es hallada. El siguiente toma el dataset de sismos_all.csv y:\n\nconvierte en variable la percepción del sismo teniendo en cuenta que la intensidad solo se registra para sismos percibidos,\nlimpia y unifica el formato de fecha de los eventos,\nextrae la información de profundidad, eliminando las unidades que forman parte del dato,\nfiltra los datos para obtener los datos del territorio continental argentino (excluyendo a Tierra del Fuego),\ny recodifica los nombres de las provincias para unificar su identificación.\n\n\n\nCódigo\n# importo datos de sismos\nsismos &lt;- vroom(\"./fuente/04_visualizacion/sismos_all.csv\")\nsismos$Fecha &lt;- as.Date(sismos$Fecha, tryFormats = c(\"%d/%m/%Y\"))\n\n# info de casi 10 años\nmin(sismos$Fecha)\nmax(sismos$Fecha)\n\n# dummy para los percibidos\nsismos &lt;- sismos %&gt;%\n  mutate(\n    Percibido = !is.na(Intensidad),\n    Magnitud = Magn.,\n    Profundidad = Profund.\n  )\n\n# quito las unidades km. en intensidad\nsismos$Profundidad &lt;- as.numeric(str_sub(sismos$Profundidad, 1,-4))\n\n# sismos en Argentina Continental (saco TdF porque se corre mucho el mapa)\nsismos_arg &lt;- sismos %&gt;%\n  filter(\n    Provincia != \"OCEANO PACIFICO\",\n    Provincia != \"CHILE\",\n    Provincia != \"MAULE - CHILE\",\n    Provincia != \"REPÚBLICA DE CHILE\",\n    Provincia != \"REPUBLICA DE CHILE\",\n    Provincia != \"SUR DE CHILE\",\n    Provincia != \"TFAIAS\",\n    Provincia != \"NORTH ISLAND, NEW ZEALAND\",\n    Provincia != \"REGION NOT FOUND.\",\n    Provincia != \"PERU\",\n    Provincia != \"PENINSULA ANTARTICA\",\n    Provincia != \"PASAJE DE DRAKE\",\n    Provincia != \"NORTHWEST OF KURIL ISLANDS\",\n    Provincia != \"NTARTIDA\",\n    Provincia != \"MAR DE SCOTIA\",\n    Provincia != \"MAR ARGENTINO\",\n    Provincia != \"ISLAS SANDWICH DEL SUR\",\n    Provincia != \"ISLAS SANDWICH\",\n    Provincia != \"ISLAS SHETLAND\",\n    Provincia != \"ISLAS SHETLAND DEL SUR\",\n    Provincia != \"ESTRECHO DE DRAKE\",\n    Provincia != \"FILIPINAS\",\n    Provincia != \"I.SANDWICH DEL SUR\",\n    Provincia != \"SECTOR ANTARTICO\",\n    Provincia != \"IS. SHETLAND DEL SUR\",\n    Provincia != \"ISLAS GEORGIA DEL SUR\",\n    Provincia != \"ISLAS GEORGIAS DEL SUR\",\n    Provincia != \"ISLAS GEORGIAS y SANDWICH DEL SUR\",\n    Provincia != \"ISLAS GIORGIA Y SANDWICH DEL SUR\",\n    Provincia != \"ISLAS ORCADAS\",\n    Provincia != \"ISLAS ORCADAS DEL SUR\",\n    Provincia != \"ATLANTICO SUR\",\n    Provincia != \"BOLIVIA\",\n    Provincia != \"PARAGUAY\",\n    Provincia != \"LIM. ARG-CHILE\",\n    Provincia != \"LIM.ARGENTINA-CHILE\",\n    Provincia != \"LIM.CHILE-ARGENTINA\",\n    Provincia != \"LIMITE ARGENTINA-CHILE\",\n    Provincia != \"LIMITE ARGENTINA CHILE\",\n    Provincia != \"TIERRA DEL FUEGO\",\n    Provincia != \"ISLAS GEORGIAS Y SANDWICH DEL SUR\"\n  )\n\ntable(sismos_arg$Provincia)\n\n# recodifico provincias\nsismos_arg &lt;- sismos_arg %&gt;%\n  mutate(\n    Provincia = recode(\n      Provincia,\n      \"BUENOS AIRES\" = \"Buenos Aires\",\n      \"CATAMARCA\" = \"Catamarca\",\n      \"CATAMARCA}\" = \"Catamarca\",\n      \"CATAMARCA LIM. TUCUMAN\" = \"Catamarca\",\n      \"CATAMARCA(LIM.CON TUCUMAN)\" = \"Catamarca\",\n      \"CATAMARCA(LIM.CON TUCUMÁN)\" = \"Catamarca\",\n      \"CHACO\" = \"Chaco\",\n      \"CHUBUT\" = \"Chubut\",\n      \"CORDOBA\" = \"Córdoba\",\n      \"CORDOBA(LIM.CON SAN LUIS)\" = \"Córdoba\",\n      \"CORDOBA LIM. SAN LUIS\" = \"Córdoba\",\n      \"CORRIENTES\" = \"Corrientes\",\n      \"ENTRE RIOS\" = \"Entre Ríos\",\n      \"FORMOSA\" = \"Formosa\",\n      \"jujuy\" = \"Jujuy\",\n      \"JUJUY\" = \"Jujuy\",\n      \"JUJUY(LIM.CON SALTA)\" = \"Jujuy\",\n      \"LA PAMPA\" = \"La Pampa\",\n      \"LA RIOJA\" = \"La Rioja\",\n      \"LA RIOJA LIM. SAN JUAN\" = \"La Rioja\",\n      \"LA RIOJA(LIM.CON CATAMARCA)\" = \"La Rioja\",\n      \"LA RIOJA(LIM.CON SAN JUAN)\" = \"La Rioja\",\n      \"LIM. CATAMARCA-TUCUMAN\" = \"Catamarca\",\n      \"LIM. LA RIOJA - SAN JUAN\" = \"La Rioja\",\n      \"LIMITE CATAMARCA - TUCUMAN\" = \"Catamarca\",\n      \"LIMITE CORDOBA - SAN LUIS\" = \"Córdoba\",\n      \"LIMITE JUJUY-SALTA\" = \"Jujuy\",\n      \"LIMITE JUJUY - SALTA\" = \"Jujuy\",\n      \"LIMITE LA RIOJA-CATAMARCA\" = \"La Rioja\",\n      \"LIMITE MENDOZA-SAN JUAN\" = \"Mendoza\",\n      \"LIMITE MENDOZA - SAN JUAN\" = \"Mendoza\",\n      \"LIMITE SALTA-JUJUY\" = \"Salta\",\n      \"LIMITE SALTA - CATAMARCA\" = \"Salta\",\n      \"LIMITE SALTA - JUJUY\" = \"Salta\",\n      \"LIMITE SAN JUAN-MENDOZA\" = \"San Juan\",\n      \"LIMITE SAN JUAN - LA RIOJA\" = \"San Juan\",\n      \"LIMITE SAN JUAN - MENDOZA\" = \"San Juan\",\n      \"LIMITE SAN JUAN SAN LUIS\" = \"San Juan\",\n      \"LIMITE SAN LUIS-SAN JUAN\" = \"San Luis\",\n      \"LIMITE TUCUMAN - CATAMARCA\" = \"Tucumán\",\n      \"MENDOZa\" = \"Mendoza\",\n      \"MENDOZA\" = \"Mendoza\",\n      \"MENDOZA(LIM.CON SAN JUAN)\" = \"Mendoza\",\n      \"MENDOZA}\" = \"Mendoza\",\n      \"MMENDOZA\" = \"Mendoza\",\n      \"NEUQUEN\" = \"Neuquén\",\n      \"RIO NEGRO\" = \"Río Negro\",\n      \"SALTA\" = \"Salta\",\n      \"SALTA (limite con Jujuy)\" = \"Salta\",\n      \"SALTA LIM. JUJUY\" = \"Salta\",\n      \"SALTA(LIM.CON JUJUY)\" = \"Salta\",\n      \"SALTA(LIM.CON TUCUMAN)\" = \"Salta\",\n      \"SAN JUAN LIM. MENDOZA\" = \"San Juan\",\n      \"SAN JUAN (LIM.CON SAN LUIS)\" = \"San Juan\",\n      \"SAN JUAN LIM. LA RIOJA\" = \"San Juan\",\n      \"SAN JUAN LIM.CON SAN LUIS\" = \"San Juan\",\n      \"SAN JUAN LIM.CON MENDOZA\" = \"San Juan\",\n      \"SAN JUAN LIM. MENDOZA\" = \"San Juan\",\n      \"SAN JUAN(LIM.ARG-CHI)\" = \"San Juan\",\n      \"SAN JUAN(LIM.CON LA RIOJA)\" = \"San Juan\",\n      \"LIMITE SAN JUAN - SAN LUIS\" = \"San Juan\",\n      \"LIMITE SAN JUAN LA RIOJA\" = \"San Juan\",\n      \"SAN JUAN(LIM.CON MENDOZA)\" = \"San Juan\",\n      \"SAN JUA\" = \"San Juan\",\n      \"SAn JUAN\" = \"San Juan\",\n      \"SAN JUAN\" = \"San Juan\",\n      \"LIMITE SAN JUAN MENDOZA\" = \"San Juan\",\n      \"SAN JUAN(LIM.CON SAN LUIS)\" = \"San Juan\",\n      \"SAN LUIS\" = \"San Luis\",\n      \"SANTA CRUZ\" = \"Santa Cruz\",\n      \"SANTIAGO DEL ESTERO\" = \"Santiago del Estero\",\n      \"SGO.DEL ESTERO LIM.CON CATAMARCA\" = \"Santiago del Estero\",\n      \"TUCUMAN\" = \"Tucumán\",\n      \"TUCUMÁN\" = \"Tucumán\",\n      \"TUCUMAN LIM. SALTA\" = \"Tucumán\",\n      \"TUCUMAN(LIM.CON CATAMARCA)\" = \"Tucumán\"\n    )\n  )\n\nsort(-table(sismos_arg$Provincia))\n\n# Elijo variables\nsismos_arg &lt;- sismos_arg %&gt;%\n  select(c(2, 3, 4, 5, 9, 10, 11, 12))\n\n\n\n5.1.1 Dataset pre-procesado: sismos-arg.csv\nPara limpiar y reducir los datos al estudio de interés, se crea un dataset reducido, sismos-arg.csv, disponible acá, a partir de los datos scrappeados del buscador del INPRES. Se incluyen datos de sismos de diferente intensidad y magnitud en la región continental del país (excluyendo Tierra del Fuego) desde el 7 de enero de 2012, hasta el 18 de mayo de 2022, y se dispone de las siguientes variables.\n\nFecha: fecha del evento sísmico, en el formato año-mes-día.\nHora: hora del evento sísmico, en el formato hora-minuto-segundo.\nLatitud: latitud del evento registrado.\nLongitud: longitud del evento registrado.\nProvincia: nombre de la provincia del evento registrado.\nPercibido: TRUE si la magnitud fue percibida, FALSE si no lo fue.\nMagnitud: magnitud del sismo en la escala de Richter.\nProfundidad: profundidad (km) registrada del sismo.\n\nEl dataset también está disponible en la librería datosIC bajo el nombre de sismos.\n\n\nCódigo\ndevtools::install_github(\"daniellaparada/datosIC\")\nlibrary(datosIC)\ndata(sismos)\n\n\n\n\nCódigo\nknitr::kable(sismos[1:10,], caption = \"Dataset reducido disponible en la librería 'datosIC'.\")\n\n\n\nDataset reducido disponible en la librería 'datosIC'.\n\n\nFecha\nHora\nLatitud\nLongitud\nProvincia\nPercibido\nMagnitud\nProfundidad\n\n\n\n\n2022-05-18\n13:09:56\n-31.820\n-67.040\nSan Juan\nFALSE\n3.0\n134\n\n\n2022-05-18\n10:18:34\n-24.216\n-67.139\nSalta\nFALSE\n3.2\n185\n\n\n2022-05-18\n09:40:09\n-31.262\n-68.708\nSan Juan\nFALSE\n3.3\n104\n\n\n2022-05-18\n09:25:43\n-32.521\n-70.085\nSan Juan\nFALSE\n2.7\n112\n\n\n2022-05-18\n08:45:59\n-28.192\n-67.376\nCatamarca\nFALSE\n2.7\n142\n\n\n2022-05-18\n08:42:33\n-32.043\n-70.030\nSan Juan\nFALSE\n2.7\n114\n\n\n2022-05-17\n23:22:48\n-23.442\n-66.846\nJujuy\nFALSE\n3.6\n210\n\n\n2022-05-17\n21:21:18\n-23.503\n-66.831\nJujuy\nFALSE\n3.6\n210\n\n\n2022-05-17\n17:17:58\n-22.794\n-66.228\nJujuy\nFALSE\n4.0\n273\n\n\n2022-05-17\n14:46:04\n-31.505\n-68.640\nSan Juan\nFALSE\n2.7\n103"
  },
  {
    "objectID": "otros-datasets.html#descripción-variables-y-fuente",
    "href": "otros-datasets.html#descripción-variables-y-fuente",
    "title": "Anexo: otros datasets",
    "section": "Descripción, variables y fuente",
    "text": "Descripción, variables y fuente\n\n\nbateria.csv\n\nDescripción: Datos del historial de capacidad de carga de una batería de Li-Ion L19M4PC2 con capacidad de fábrica de 80.000 mWh en una Notebook LENOVO 81YT con 505 ciclos de carga.\nVariables:\n\nfecha_desde: fecha de inicio del período.\nfecha_hasta: fecha de finalización del período.\ncarga: carga máxima alcanzada (mWh) durante el período.\n\nFuente: Reporte generado a partir de la instrucción powercfg /batteryreport en Windows 11.\n\n\n\n\nnombres-arg.csv\n\nDescripción: Datos de.\nVariables:\n\nXXX:\n\nFuente: XXX"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Bibliografía",
    "section": "",
    "text": "Ver si va (ejemplo dummy)"
  }
]